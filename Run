from __future__ import annotations

import argparse
import re
import time
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Sequence

import pandas as pd
from openpyxl import load_workbook

# -------------------- Config --------------------

QUESTION_SHEETS: Dict[str, Sequence[str]] = {
    "Q1": ("q1", "question 1", "q1 "),
    "Q2": ("q2", "question 2", "q2 "),
    "Q3": ("q3", "question 3", "q3 "),
    "Q4": ("q4", "question 4", "q4 "),
    "Q5": ("q5", "question 5", "q5 "),
}

# Canonical month/quarter names to capture if present
MONTHS = ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"]
QUARTERS = ["Q1","Q2","Q3","Q4"]

# Dimension columns we expect (with wide alias mapping)
DIM_HEADERS = ["entity", "employment detail", "worker category", "institution"]

HEADER_ALIASES = {
    # entity
    "entity": "entity",
    "entity / group": "entity",
    "entity/group": "entity",
    "entity group": "entity",
    "reporting entity": "entity",
    "bank": "entity",
    "company": "entity",

    # employment detail
    "employment detail": "employment detail",
    "employment": "employment detail",
    "employment type": "employment detail",

    # worker category
    "worker category": "worker category",
    "category": "worker category",
    "occupation group": "worker category",
    "job category": "worker category",

    # institution
    "institution": "institution",
    "fi": "institution",
    "institution name": "institution",
    "reporting fi": "institution",
    "fi name": "institution",
}

# How far down to scan for headers (in case headers start around row 7–12)
HEADER_SCAN_ROWS = 60


# -------------------- Models --------------------

@dataclass
class CoverMeta:
    year: Optional[int]
    quarter_label: Optional[str]
    reporting_entity: Optional[str] = None

@dataclass
class StagedRow:
    file_name: str
    question: str
    entity_group: str
    employment_detail: str
    worker_category: str
    institution: str
    Jan: float = 0.0; Feb: float = 0.0; Mar: float = 0.0
    Apr: float = 0.0; May: float = 0.0; Jun: float = 0.0
    Jul: float = 0.0; Aug: float = 0.0; Sep: float = 0.0
    Oct: float = 0.0; Nov: float = 0.0; Dec: float = 0.0
    Q1: float = 0.0; Q2: float = 0.0; Q3: float = 0.0; Q4: float = 0.0
    year: Optional[int] = None
    quarter: Optional[str] = None


# -------------------- Helpers --------------------

def _norm(s: str) -> str:
    return re.sub(r"\s+", " ", str(s)).strip().lower()

def _map_header(raw: str) -> str:
    key = _norm(raw)
    return HEADER_ALIASES.get(key, raw)

def _looks_like_question(target: str, sheet: str) -> bool:
    s = _norm(sheet)
    for pat in QUESTION_SHEETS.get(target, ()):
        if pat in s:
            return True
    return False

def _is_temp_or_hidden(name: str) -> bool:
    return name.startswith("~$") or name.lower().endswith(".tmp")

def _find_cover_sheet(wb) -> Optional[str]:
    for nm in wb.sheetnames:
        if _norm(nm) in ("cover","metadata","meta","front","summary"):
            return nm
    return wb.sheetnames[0] if wb.sheetnames else None

def _read_cover_meta(wb) -> CoverMeta:
    try:
        nm = _find_cover_sheet(wb)
        if not nm:
            return CoverMeta(None, None, None)
        ws = wb[nm]
        year = None
        qlab = None
        ent = None

        # Very common locations; harmless if missing
        try:
            y = ws["B2"].value
            if y is not None and str(y).strip().isdigit():
                year = int(str(y).strip())
        except Exception:
            pass
        try:
            qlab = ws["B3"].value
        except Exception:
            pass
        try:
            ent = ws["B1"].value
        except Exception:
            pass

        return CoverMeta(year, qlab, ent)
    except Exception:
        return CoverMeta(None, None, None)

def _header_score(cells: List[str]) -> int:
    """
    Score how much a row looks like our header:
    +2 for each dimension we find
    +1 for each month/quarter we find
    """
    lowers = [_norm(c) for c in cells]
    score = 0
    # dimensions
    for want in DIM_HEADERS:
        if want in lowers:
            score += 2
    # months/quarters
    for m in MONTHS + QUARTERS:
        if _norm(m) in lowers:
            score += 1
    return score

def _first_header_row(df: pd.DataFrame, verbose: bool=False, file_hint: str="", sheet_hint: str="") -> Optional[int]:
    best_i = None
    best_score = -1
    max_scan = min(HEADER_SCAN_ROWS, len(df))
    for i in range(max_scan):
        cells = [str(x) for x in df.iloc[i].tolist()]
        # map common aliases so scoring works
        mapped = [_map_header(c) for c in cells]
        sc = _header_score(mapped)
        if sc > best_score:
            best_score = sc
            best_i = i
    if best_score >= 6:  # ~ 3 dims (2*3) or 2 dims + some months
        return best_i
    if verbose:
        print(f"  [DEBUG] No good header in first {max_scan} rows (best_score={best_score}) "
              f"-> {file_hint} :: {sheet_hint}")
    return None


def _extract_table_from_sheet(
    book_path: Path, sheet_name: str, qlabel: str, meta: CoverMeta, verbose: bool=False
) -> List[StagedRow]:
    try:
        df = pd.read_excel(book_path, sheet_name=sheet_name, header=None, engine="openpyxl")
    except Exception as e:
        if verbose:
            print(f"  [WARN] Cannot read sheet {sheet_name}: {e}")
        return []

    hdr_row = _first_header_row(df, verbose=verbose, file_hint=book_path.name, sheet_hint=sheet_name)
    if hdr_row is None:
        return []

    raw_headers = [str(x) for x in df.iloc[hdr_row].tolist()]
    headers = [_map_header(h) for h in raw_headers]
    data = df.iloc[hdr_row + 1:].copy()
    data.columns = headers

    needed = {"entity", "employment detail", "worker category", "institution"}
    present = set(_norm(c) for c in data.columns)
    if not needed.issubset(present):
        if verbose:
            print(f"  [DEBUG] Missing dimension columns in {book_path.name} :: {sheet_name} -> have: {sorted(present)}")
        return []

    # coerce numerics
    for col in MONTHS + QUARTERS:
        if col in data.columns:
            data[col] = pd.to_numeric(data[col], errors="coerce").fillna(0)

    out: List[StagedRow] = []
    for _, r in data.iterrows():
        ent = r.get("entity", None)
        if pd.isna(ent) or str(ent).strip() == "":
            # assume blank spacer/end
            continue

        row = StagedRow(
            file_name=book_path.name,
            question=qlabel,
            entity_group=str(r.get("entity","")).strip(),
            employment_detail=str(r.get("employment detail","")).strip(),
            worker_category=str(r.get("worker category","")).strip(),
            institution=str(r.get("institution","")).strip(),
            year=meta.year, quarter=meta.quarter_label,
        )
        for m in MONTHS:
            if m in data.columns:
                setattr(row, m, float(r.get(m, 0) or 0))
        for q in QUARTERS:
            if q in data.columns:
                setattr(row, q, float(r.get(q, 0) or 0))

        out.append(row)

    return out


def _extract_from_file_all(path: Path, verbose: bool=False) -> List[StagedRow]:
    if _is_temp_or_hidden(path.name):
        return []
    try:
        wb = load_workbook(str(path), data_only=True, read_only=True)
    except Exception as e:
        if verbose:
            print(f"[WARN] Skip {path.name}: cannot open ({e})")
        return []

    try:
        meta = _read_cover_meta(wb)
        rows: List[StagedRow] = []

        sheetnames = list(wb.sheetnames)

        # Try strict matching first; then a relaxed pass (any sheet containing "q1"/"q2"/...)
        for qlabel in ["Q1","Q2","Q3","Q4","Q5"]:
            strict = [s for s in sheetnames if _looks_like_question(qlabel, s)]
            candidates = strict or [s for s in sheetnames if qlabel.lower() in _norm(s)]
            # Drop obvious non-data sheets
            candidates = [s for s in candidates if _norm(s) not in ("cover","about","metadata","meta","summary")]
            if not candidates and verbose:
                print(f"  [INFO] No sheets for {qlabel} in {path.name}")

            for s in candidates:
                if verbose:
                    print(f"    {qlabel} <- {s}")
                rows.extend(_extract_table_from_sheet(path, s, qlabel, meta, verbose=verbose))

        return rows
    finally:
        try:
            wb.close()
        except Exception:
            pass


def _collect_excel_files(root: Path, limit: Optional[int]=None) -> List[Path]:
    files: List[Path] = []
    for ext in ("*.xlsx","*.xlsm"):
        files.extend([p for p in root.rglob(ext) if not p.name.startswith("~$")])
    files.sort()
    if limit:
        files = files[:limit]
    return files


# -------------------- CLI --------------------

def main() -> int:
    ap = argparse.ArgumentParser(
        description="Extract Q1–Q5 raw rows from submissions into one staging workbook (no calculations)."
    )
    ap.add_argument("--inputs", required=True, help="Folder to scan recursively")
    ap.add_argument("--out", default=None, help="Output .xlsx (default: <inputs>/stage_all_questions_<ts>.xlsx)")
    ap.add_argument("--limit", type=int, default=None, help="Limit files (debug)")
    ap.add_argument("--verbose", action="store_true", help="Verbose logging")
    args = ap.parse_args()

    in_root = Path(args.inputs)
    if not in_root.exists():
        print(f"[ERROR] Inputs folder not found: {in_root}")
        return 2

    t0 = time.perf_counter()
    files = _collect_excel_files(in_root, limit=args.limit)
    if args.verbose:
        print(f"[INFO] Files to scan: {len(files)}")

    all_rows: List[StagedRow] = []
    for i, p in enumerate(files, start=1):
        if args.verbose:
            print(f"[{i}/{len(files)}] {p.name}")
        try:
            rs = _extract_from_file_all(p, verbose=args.verbose)
            if rs:
                all_rows.extend(rs)
            elif args.verbose:
                print(f"  [INFO] -> 0 rows from {p.name}")
        except Exception as e:
            if args.verbose:
                print(f"  [WARN] {p.name}: {e}")

    if not all_rows:
        print("[WARN] No rows extracted. Run again with --verbose to see header detection and sheet matching hints.")
        return 1

    cols = [
        "file_name","question",
        "entity_group","employment_detail","worker_category","institution",
        *MONTHS, *QUARTERS,
        "year","quarter",
    ]
    df = pd.DataFrame([asdict(r) for r in all_rows])
    # ensure column order / add missing columns
    for c in cols:
        if c not in df.columns:
            df[c] = 0 if c in MONTHS+QUARTERS else ""
    df = df[cols]

    out_path = Path(args.out) if args.out else (in_root / f"stage_all_questions_{time.strftime('%Y%m%d_%H%M%S')}.xlsx")
    out_path.parent.mkdir(parents=True, exist_ok=True)
    with pd.ExcelWriter(out_path, engine="openpyxl") as xw:
        df.to_excel(xw, sheet_name="Stage", index=False)

    t1 = time.perf_counter()
    print(f"[DONE] Wrote {len(df):,} rows -> {out_path}")
    print(f"[TIMER] Total: {t1 - t0:0.2f}s")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())
