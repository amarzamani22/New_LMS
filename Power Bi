# app.py
# -----------------------------
# QC Intelligence Console (Streamlit)
# -----------------------------
# Features:
# - Explore: Plotly chart with MoM band + 3M rolling mean (fixed), optional comparison year
# - Anomalies: Clear alert flags per period + severity label (True/Probable/Watchlist)
# - Attribution: Only for True Outliers (All FI -> Sector -> Subsector -> Institution)
# - Report: Batch monthly scan & CSV export
# -----------------------------

import os
import re
import numpy as np
import pandas as pd
import streamlit as st
import plotly.graph_objects as go

# ---------- Page ----------
st.set_page_config(page_title="QC Intelligence Console", page_icon="ðŸ“Š", layout="wide")
st.markdown("""
<style>
    .stApp { background-color:#F5F7FB; }
    .kpi-card {
        padding:14px; border-radius:10px; background:#fff; border:1px solid #e7e7e7;
        box-shadow:0 2px 8px rgba(0,0,0,0.03); text-align:center;
    }
    .subtle { color:#666; font-size:0.9rem; }
</style>
""", unsafe_allow_html=True)

# ---------- Constants ----------
ALL_MONTHS = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']
SHEET_MAP = {
    'Q1A: Employees': 'QC_Q1A_Main',
    'Q2A: Salary': 'QC_Q2A_Main',
    'Q3: Hours Worked': 'QC_Q3',
    'Q4: Vacancies': 'QC_Q4',
    'Q5: Separations': 'QC_Q5'
}

# Composite label thresholds (we keep numbers internal; UI shows labels only)
COMPOSITE_LABELS = [
    (0.75, "True Outlier"),
    (0.65, "Probable Outlier"),
    (0.50, "Watchlist"),
]

# Rolling (fixed â€” as requested)
ROLL_W = 3
ROLL_KSIG = 2.5      # std-dev multiple for 0.6 score
ROLL_KSIG_STRONG = 3.0
ROLL_REL = 0.25      # 25% from rolling mean (fallback if std is tiny)
ROLL_REL_STRONG = 0.40

# Weights (kept internal; monthly vs quarterly)
WEIGHTS_MONTHLY   = dict(MoM=0.35, YoY=0.30, IQR=0.20, ROLL=0.15)
WEIGHTS_QUARTERLY = dict(MoM=0.25, YoY=0.40, IQR=0.25, ROLL=0.10)

# ---------- Data Loaders ----------
@st.cache_data
def load_data(year: int|None, sheet_name: str):
    if year is None:
        return None
    file_path = f"submission/qc_workbook_{year}.xlsx"
    if not os.path.exists(file_path):
        return f"Error: file not found â†’ {file_path}"
    try:
        df = pd.read_excel(file_path, sheet_name=sheet_name, header=5)
        df.dropna(axis=1, how='all', inplace=True)
        df.rename(columns={'Q1.1':'Q1_Total','Q2.1':'Q2_Total','Q3.1':'Q3_Total','Q4.1':'Q4_Total'}, inplace=True)
        return df
    except Exception as e:
        return f"Error reading '{sheet_name}' from {file_path}: {e}"

@st.cache_data
def get_reporting_quarter(year: int):
    file_path = f"submission/qc_workbook_{year}.xlsx"
    try:
        about_df = pd.read_excel(file_path, sheet_name="_About", header=None)
        quarter_row = about_df[about_df[0] == 'Quarter']
        if not quarter_row.empty:
            return int(re.search(r'\d+', str(quarter_row.iloc[0, 1])).group())
    except Exception:
        pass
    return 4

@st.cache_data
def load_hierarchy_map(path="submission/entity_hierarchy.csv"):
    if not os.path.exists(path):
        return None, "Hierarchy map not found. Place submission/entity_hierarchy.csv (columns: Institution,Sector,Subsector)."
    try:
        h = pd.read_csv(path)
        req = {'Institution','Sector','Subsector'}
        if not req.issubset(set(h.columns)):
            return None, f"Hierarchy map missing columns. Need {req}"
        return h, None
    except Exception as e:
        return None, f"Error reading hierarchy map: {e}"

# ---------- Helpers ----------
def _row_filter(df, entity, worker_cat, subq):
    cond = (df['Entity / Group'] == entity) & (df['Worker Category'] == worker_cat)
    if 'Subquestion' in df.columns:
        cond &= (df['Subquestion'] == subq)
    return df[cond]

def build_quarter_series(data_row, year, reporting_quarter):
    if data_row.empty: return pd.Series(dtype=float)
    labels, vals = [], []
    have_any = False
    # Prefer Qx_Total when present
    for q in range(1, reporting_quarter+1):
        col = f'Q{q}_Total'
        if col in data_row.columns:
            v = pd.to_numeric(data_row.iloc[0][col], errors='coerce')
            if not pd.isna(v):
                have_any = True
                labels.append(f"Q{q} {year}"); vals.append(float(v))
    # Compute from months for missing quarters
    if not have_any or len(labels) < reporting_quarter:
        q_map = {1: ALL_MONTHS[0:3], 2: ALL_MONTHS[3:6], 3: ALL_MONTHS[6:9], 4: ALL_MONTHS[9:12]}
        present_qs = {int(l.split()[0][1:]) for l in labels}
        for q in range(1, reporting_quarter+1):
            if q in present_qs: continue
            mlist = [m for m in q_map[q] if m in data_row.columns]
            if mlist:
                ser = pd.to_numeric(data_row[mlist].iloc[0], errors='coerce').astype(float)
                if not np.all(np.isnan(ser.values)):
                    labels.append(f"Q{q} {year}")
                    vals.append(float(np.nansum(ser.values)))
    if not labels: return pd.Series(dtype=float)
    order = np.argsort([int(l.split()[0][1:]) for l in labels])
    labels = [labels[i] for i in order]; vals = [vals[i] for i in order]
    return pd.Series(vals, index=labels, dtype=float)

def _rolling(series: pd.Series, window=ROLL_W):
    m = series.rolling(window=window, min_periods=max(2, window//2)).mean()
    s = series.rolling(window=window, min_periods=max(2, window//2)).std()
    return m, s

def _compose_label(score: float, consensus_ok: bool):
    if not consensus_ok:
        return ""
    for thr, name in COMPOSITE_LABELS:
        if score >= thr:
            return name
    return ""

def _weights(view):  # Monthly vs Quarterly
    return WEIGHTS_MONTHLY if view == "Monthly" else WEIGHTS_QUARTERLY

# ---------- 4-Pillar Alerts ----------
def score_pillars(series, prior_series, mom_pct_thresh, mom_abs_floor, yoy_pct_thresh, iqr_k, view):
    """
    Returns a DataFrame (index=period) with columns:
    - Alerts (list[str]) e.g. ["High Volatility","YoY Anomaly"]
    - Label (str) in {"True Outlier","Probable Outlier","Watchlist",""}
    - Composite (float) kept internal
    - Value (float), RollingMean (float)
    """
    idx = list(series.index)
    out_rows = []

    # IQR bounds
    valid = series.dropna()
    if len(valid) >= 4:
        q1, q3 = valid.quantile(0.25), valid.quantile(0.75)
        iqr = q3 - q1
        lb, ub = q1 - iqr_k*iqr, q3 + iqr_k*iqr
    else:
        lb = ub = iqr = None

    r_mean, r_std = _rolling(series, ROLL_W)
    W = _weights(view)

    for i, p in enumerate(idx):
        v = series.iloc[i]
        alerts = []
        # Pillar scores for internal composite
        s_mom = s_yoy = s_iqr = s_roll = 0.0

        # MoM Shock
        if i > 0 and not pd.isna(v):
            prev = series.iloc[i-1]
            if not pd.isna(prev) and prev != 0:
                d_abs = v - prev
                d_pct = d_abs / prev
                if abs(d_pct) > mom_pct_thresh and abs(d_abs) > mom_abs_floor:
                    alerts.append("High Volatility (MoM)")
                    s_mom = 1.0 if abs(d_pct) > max(0.5, mom_pct_thresh*2) else 0.6

        # YoY
        if prior_series is not None and p in prior_series.index and not pd.isna(v):
            prev_y = prior_series.loc[p]
            if not pd.isna(prev_y) and prev_y != 0:
                yoy = (v - prev_y) / prev_y
                if abs(yoy) > yoy_pct_thresh:
                    alerts.append("YoY Anomaly")
                    s_yoy = 1.0 if abs(yoy) > max(0.60, yoy_pct_thresh*2) else 0.6

        # IQR
        if lb is not None and not pd.isna(v):
            if v < lb or v > ub:
                alerts.append("IQR Range Break")
                # distance approx to grade 0.6 vs 1.0
                dist = 0.0
                if iqr and iqr != 0:
                    if v > ub: dist = (v - ub)/iqr
                    elif v < lb: dist = (lb - v)/iqr
                s_iqr = 1.0 if dist >= 1.0 else 0.6

        # Rolling Deviation (3M)
        mu = r_mean.iloc[i] if len(r_mean) > i else np.nan
        sd = r_std.iloc[i] if len(r_std) > i else np.nan
        if not pd.isna(v) and not pd.isna(mu):
            if not pd.isna(sd) and sd > 0:
                z = abs(v - mu)/sd
                if z >= ROLL_KSIG_STRONG:
                    alerts.append("Rolling Break (3M)")
                    s_roll = 1.0
                elif z >= ROLL_KSIG:
                    alerts.append("Rolling Break (3M)")
                    s_roll = 0.6
            else:
                # fallback to relative from mean
                if mu != 0:
                    rel = abs(v - mu)/abs(mu)
                    if rel >= ROLL_REL_STRONG:
                        alerts.append("Rolling Break (3M)")
                        s_roll = 1.0
                    elif rel >= ROLL_REL:
                        alerts.append("Rolling Break (3M)")
                        s_roll = 0.6

        # Composite & label (consensus)
        comp = (W['MoM']*s_mom + W['YoY']*s_yoy + W['IQR']*s_iqr + W['ROLL']*s_roll)
        strong = sum(x >= 0.6 for x in [s_mom, s_yoy, s_iqr, s_roll])
        any1 = any(abs(x - 1.0) < 1e-9 for x in [s_mom, s_yoy, s_iqr, s_roll])
        any04 = sum(x >= 0.4 for x in [s_mom, s_yoy, s_iqr, s_roll]) >= 2
        consensus_ok = (strong >= 2) or (any1 and any04)
        label = _compose_label(comp, consensus_ok)

        out_rows.append(dict(
            Period=p, Value=float(v) if not pd.isna(v) else np.nan,
            RollingMean=float(mu) if not pd.isna(mu) else np.nan,
            Alerts=alerts, Label=label, Composite=float(comp)
        ))

    df = pd.DataFrame(out_rows).set_index("Period")
    # Sort: True â†’ Probable â†’ Watchlist â†’ (none), then by Composite desc
    level_order = {"True Outlier":0, "Probable Outlier":1, "Watchlist":2, "":3}
    df = df.assign(_ord=df['Label'].map(level_order)).sort_values(['_ord','Composite'], ascending=[True,False]).drop(columns=['_ord'])
    return df

# ---------- Plot ----------
def plot_series(series_cur, series_prior, title, show_mom_band=True, show_rolling=True):
    x = list(series_cur.index)
    y = series_cur.values.astype(float)

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=x, y=y, mode='lines+markers', name='Current',
        hovertemplate='Period: %{x}<br>Value: %{y:,.0f}<extra></extra>'
    ))
    if series_prior is not None and not series_prior.empty:
        fig.add_trace(go.Scatter(
            x=list(series_prior.index),
            y=series_prior.values.astype(float),
            mode='lines+markers', name='Comparison', line=dict(dash='dash'),
            hovertemplate='Period: %{x}<br>Value: %{y:,.0f}<extra></extra>'
        ))

    # MoM Â±25% band
    if show_mom_band and len(y) >= 2:
        upper = [None] + [y[i-1]*1.25 for i in range(1, len(y))]
        lower = [None] + [y[i-1]*0.75 for i in range(1, len(y))]
        # lower boundary
        fig.add_trace(go.Scatter(x=x, y=lower, mode='lines', line=dict(width=0), showlegend=False, hoverinfo='skip'))
        # upper with fill
        fig.add_trace(go.Scatter(x=x, y=upper, mode='lines', line=dict(width=0), fill='tonexty',
                                 name='MoM Â±25% Range', opacity=0.15, hoverinfo='skip'))

    # Rolling mean (3M)
    if show_rolling and len(y) >= 2:
        r_mean = pd.Series(y).rolling(window=ROLL_W, min_periods=max(2, ROLL_W//2)).mean().values
        fig.add_trace(go.Scatter(
            x=x, y=r_mean, mode='lines', name=f'Rolling Mean ({ROLL_W}M)', hovertemplate='Rolling: %{y:,.0f}<extra></extra>',
            line=dict(width=1.5)
        ))

    fig.update_layout(
        title=title, hovermode='x unified',
        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='left', x=0),
        margin=dict(l=10, r=10, t=50, b=10)
    )
    fig.update_xaxes(tickangle=45)
    st.plotly_chart(fig, use_container_width=True)

# ---------- Attribution ----------
def aggregate_monthly(df_slice, months):
    work = df_slice.copy()
    for m in months:
        if m in work.columns:
            work[m] = pd.to_numeric(work[m], errors='coerce')
    return work

def build_level_series(df_sheet, cols, hmap):
    merged = df_sheet.merge(hmap, left_on='Entity / Group', right_on='Institution', how='left')

    inst = {}
    for name, g in merged.groupby('Institution', dropna=False):
        if name is None or pd.isna(name): continue
        s = g[cols].sum(numeric_only=True); s.index = cols; inst[name] = s

    sub = {}
    for (sec, subsec), g in merged.groupby(['Sector','Subsector'], dropna=False):
        if pd.isna(sec) or pd.isna(subsec): continue
        s = g[cols].sum(numeric_only=True); s.index = cols; sub[(sec, subsec)] = s

    secd = {}
    for sec, g in merged.groupby('Sector', dropna=False):
        if pd.isna(sec): continue
        s = g[cols].sum(numeric_only=True); s.index = cols; secd[sec] = s

    allfi = merged[cols].sum(numeric_only=True); allfi.index = cols
    return dict(AllFI=allfi, Sector=secd, Subsector=sub, Institution=inst)

def _delta_prev(series, period):
    if period not in series.index: return np.nan
    i = list(series.index).index(period)
    if i == 0: return np.nan
    v, pv = series.iloc[i], series.iloc[i-1]
    if pd.isna(v) or pd.isna(pv): return np.nan
    return v - pv

def attribute_path(period, agg):
    out = {'Period': period}
    allfi = agg['AllFI']
    out['AllFI_value'] = allfi.get(period, np.nan)
    out['AllFI_delta'] = _delta_prev(allfi, period)

    # Sector
    s_contrib = {sec: _delta_prev(s, period) for sec, s in agg['Sector'].items()}
    sec_best = max(s_contrib, key=lambda k: abs(s_contrib[k]) if not pd.isna(s_contrib[k]) else -1) if s_contrib else None
    out['Sector'] = sec_best; out['Sector_delta'] = s_contrib.get(sec_best, np.nan) if sec_best else np.nan

    # Subsector within sector
    sub_choices = {k: v for k, v in agg['Subsector'].items() if k[0] == sec_best} if sec_best else {}
    sub_contrib = {sub: _delta_prev(s, period) for sub, s in sub_choices.items()}
    sub_best = max(sub_contrib, key=lambda k: abs(sub_contrib[k]) if not pd.isna(sub_contrib[k]) else -1) if sub_contrib else None
    out['Subsector'] = sub_best[1] if sub_best else None
    out['Subsector_delta'] = sub_contrib.get(sub_best, np.nan) if sub_best else np.nan

    # Institution (top absolute Î” within chosen subsector if available, else global)
    if sub_best:
        chosen_sec, chosen_sub = sub_best
        inst_contrib = {}
        for inst, s in agg['Institution'].items():
            # In a stricter version, filter institutions by subsector via a lookup map; here we pick global top Î” for simplicity.
            inst_contrib[inst] = _delta_prev(s, period)
    else:
        inst_contrib = {inst: _delta_prev(s, period) for inst, s in agg['Institution'].items()}

    inst_best = max(inst_contrib, key=lambda k: abs(inst_contrib[k]) if not pd.isna(inst_contrib[k]) else -1) if inst_contrib else None
    out['Institution'] = inst_best
    out['Institution_delta'] = inst_contrib.get(inst_best, np.nan) if inst_best else np.nan
    return out

# ---------- Sidebar ----------
st.sidebar.title("Controls")
current_year = st.sidebar.selectbox("Current Year", [2026, 2025, 2024, 2023], index=1)
comparison_year = st.sidebar.selectbox("Comparison Year", [2025, 2024, 2023, None], index=0)
dataset = st.sidebar.selectbox("Dataset", list(SHEET_MAP.keys()))
time_view = st.sidebar.radio("Timeframe", ['Monthly','Quarterly'], horizontal=True)
st.sidebar.markdown("---")
abs_floor = st.sidebar.slider("Absolute Change floor", 10, 1000, 50, 10)
iqr_k = st.sidebar.slider("IQR Sensitivity (k)", 1.0, 3.0, 1.5, 0.1)
yoy_pct = st.sidebar.slider("YoY % Threshold", 0, 100, 30, 5, format="%d%%")
yoy_thresh = yoy_pct / 100.0

# ---------- Load data ----------
sheet_name = SHEET_MAP[dataset]
df_current = load_data(current_year, sheet_name)
df_prior = load_data(comparison_year, sheet_name) if comparison_year else None
if isinstance(df_current, str):
    st.error(df_current)
    st.stop()

rq = get_reporting_quarter(current_year)
months_to_analyze = [m for m in ALL_MONTHS[:rq*3] if m in df_current.columns]

# Entity filters
entity = st.selectbox("Entity / Group", options=df_current['Entity / Group'].unique())
if 'Subquestion' in df_current.columns and df_current[df_current['Entity / Group'] == entity]['Subquestion'].nunique() > 1:
    subquestion = st.selectbox("Subquestion", options=df_current[df_current['Entity / Group'] == entity]['Subquestion'].unique())
    worker_cat = st.selectbox("Worker Category", options=df_current[(df_current['Entity / Group'] == entity) & (df_current['Subquestion'] == subquestion)]['Worker Category'].unique())
    row_cur = _row_filter(df_current, entity, worker_cat, subquestion)
else:
    subquestion = "N/A"
    worker_cat = st.selectbox("Worker Category", options=df_current[df_current['Entity / Group'] == entity]['Worker Category'].unique())
    row_cur = _row_filter(df_current, entity, worker_cat, subquestion)

row_prior = None
if not isinstance(df_prior, str) and df_prior is not None:
    row_prior = _row_filter(df_prior, entity, worker_cat, subquestion)

# Build series
if time_view == 'Monthly':
    series_cur = pd.Series(dtype=float)
    if months_to_analyze:
        series_cur = pd.to_numeric(row_cur[months_to_analyze].iloc[0], errors='coerce').astype(float)
        series_cur.index = months_to_analyze
    series_prior = None
    if row_prior is not None and not row_prior.empty and all(m in row_prior.columns for m in months_to_analyze):
        series_prior = pd.to_numeric(row_prior[months_to_analyze].iloc[0], errors='coerce').astype(float)
else:
    series_cur = build_quarter_series(row_cur, current_year, rq)
    series_prior = None
    if row_prior is not None and not row_prior.empty and comparison_year:
        rq_prior = get_reporting_quarter(comparison_year)
        series_prior = build_quarter_series(row_prior, comparison_year, rq_prior)

# ---------- KPI Header ----------
st.markdown("### QC Intelligence Console")
colA, colB, colC, colD = st.columns(4)
with colA: st.markdown(f"<div class='kpi-card'><div class='subtle'>Current Year</div><h3>{current_year}</h3></div>", unsafe_allow_html=True)
with colB: st.markdown(f"<div class='kpi-card'><div class='subtle'>Timeframe</div><h3>{time_view}</h3></div>", unsafe_allow_html=True)
with colC: st.markdown(f"<div class='kpi-card'><div class='subtle'>Dataset</div><h3>{dataset}</h3></div>", unsafe_allow_html=True)
with colD:
    latest_val = series_cur.iloc[-1] if not series_cur.empty else np.nan
    st.markdown(f"<div class='kpi-card'><div class='subtle'>Latest Value</div><h3>{latest_val:,.0f}</h3></div>", unsafe_allow_html=True)

# ---------- Tabs ----------
tab1, tab2, tab3, tab4 = st.tabs(["ðŸ”Ž Explore", "ðŸš¨ Anomalies", "ðŸ§­ Attribution", "ðŸ§¾ Report"])

# Explore
with tab1:
    if series_cur.empty or series_cur.isnull().all():
        st.warning("No data for selected filters/period.")
    else:
        title = f"{'Monthly' if time_view=='Monthly' else 'Quarterly'} Trend â€” {entity} | {worker_cat}"
        plot_series(series_cur, series_prior, title, show_mom_band=True, show_rolling=True)

# Anomalies
with tab2:
    if series_cur.empty or series_cur.isnull().all():
        st.info("No data to analyze.")
    else:
        # MoM threshold fixed at 25% (as in your original logic)
        alerts_df = score_pillars(
            series_cur, series_prior,
            mom_pct_thresh=0.25, mom_abs_floor=abs_floor,
            yoy_pct_thresh=yoy_thresh, iqr_k=iqr_k, view=time_view
        )

        # Show a clean alerts table
        show = alerts_df.copy()
        show['Alerts'] = show['Alerts'].apply(lambda L: ", ".join(sorted(set(L))))
        show = show[['Value','RollingMean','Alerts','Label']]
        st.markdown("**Alerts (sorted by severity):**")
        st.dataframe(
            show.style.format({'Value':'{:,.0f}','RollingMean':'{:,.0f}'}),
            use_container_width=True
        )

        # Mark points on the chart (optional): list of flagged periods (label not empty)
        flagged_periods = alerts_df.index[alerts_df['Label'] == "True Outlier"].tolist()

# Attribution (only for True Outliers)
with tab3:
    hmap, herr = load_hierarchy_map()
    if herr:
        st.info(herr)
    else:
        # Build a slice of the current sheet for the same subquestion/worker-cat across all institutions
        slice_df = df_current.copy()
        if 'Subquestion' in slice_df.columns:
            slice_df = slice_df[slice_df['Subquestion'] == subquestion]
        slice_df = slice_df[slice_df['Worker Category'] == worker_cat].copy()

        if time_view == 'Monthly':
            if not months_to_analyze:
                st.warning("No months available.")
            elif series_cur.empty:
                st.warning("Load a series in Explore first.")
            else:
                # Find True Outliers in the current entity series
                alerts_df = score_pillars(
                    series_cur, series_prior,
                    mom_pct_thresh=0.25, mom_abs_floor=abs_floor,
                    yoy_pct_thresh=yoy_thresh, iqr_k=iqr_k, view=time_view
                )
                critical = alerts_df[alerts_df['Label'] == "True Outlier"]
                if critical.empty:
                    st.info("No True Outliers under current thresholds â€” attribution not required.")
                else:
                    # Let user pick which critical period to explain
                    period_pick = st.selectbox("Pick a period (True Outlier) to explain", list(critical.index))
                    agg_df = aggregate_monthly(slice_df, months_to_analyze)
                    agg = build_level_series(agg_df, months_to_analyze, hmap)

                    path = attribute_path(period_pick, agg)
                    if np.isnan(path.get('AllFI_delta', np.nan)):
                        st.info("Not enough data to compute contributions for the chosen period.")
                    else:
                        st.markdown(
                            f"**Result:** High movement in **All FI** (Î” {path['AllFI_delta']:+,.0f}) "
                            f"is primarily from **{path['Sector']}** (Î” {path['Sector_delta']:+,.0f}), "
                            f"specifically **{path.get('Subsector','-')}** â€” "
                            f"**{path.get('Institution','-')}** (Î” {path['Institution_delta']:+,.0f}) at **{period_pick}**."
                        )
                        # Top contributors table
                        inst_rows = []
                        for inst, s in agg['Institution'].items():
                            d = _delta_prev(s, period_pick)
                            inst_rows.append((inst, s.get(period_pick, np.nan), d))
                        top_inst = pd.DataFrame(inst_rows, columns=['Institution','Value','Î” from prev']).dropna()
                        top_inst['absÎ”'] = top_inst['Î” from prev'].abs()
                        top_inst = top_inst.sort_values('absÎ”', ascending=False).drop(columns='absÎ”').head(10)
                        st.dataframe(top_inst, use_container_width=True)
                        st.download_button("ðŸ“¥ Download top contributions (CSV)",
                                           top_inst.to_csv(index=False).encode('utf-8'), "attribution.csv",
                                           "text/csv", use_container_width=True)

        else:  # Quarterly attribution
            periods = list(series_cur.index)
            if not periods:
                st.warning("No quarters available.")
            elif series_cur.empty:
                st.warning("Load a series in Explore first.")
            else:
                alerts_df = score_pillars(
                    series_cur, series_prior,
                    mom_pct_thresh=0.25, mom_abs_floor=abs_floor,
                    yoy_pct_thresh=yoy_thresh, iqr_k=iqr_k, view=time_view
                )
                critical = alerts_df[alerts_df['Label'] == "True Outlier"]
                if critical.empty:
                    st.info("No True Outliers under current thresholds â€” attribution not required.")
                else:
                    period_pick = st.selectbox("Pick a quarter (True Outlier) to explain", list(critical.index))

                    # Build quarterly matrix per institution for selected slice
                    wide = pd.DataFrame(index=slice_df['Entity / Group'].values, columns=periods, dtype=float)
                    for i, r in slice_df.iterrows():
                        s = build_quarter_series(pd.DataFrame([r]), current_year, rq)
                        for p in periods:
                            wide.loc[r['Entity / Group'], p] = s.get(p, np.nan)
                    tmp = slice_df[['Entity / Group']].drop_duplicates().copy()
                    for p in periods: tmp[p] = wide[p].values
                    tmp['Worker Category'] = worker_cat
                    if 'Subquestion' in slice_df.columns:
                        tmp['Subquestion'] = subquestion

                    agg = build_level_series(tmp, periods, hmap)
                    path = attribute_path(period_pick, agg)
                    if np.isnan(path.get('AllFI_delta', np.nan)):
                        st.info("Not enough data to compute contributions for the chosen quarter.")
                    else:
                        st.markdown(
                            f"**Result:** High movement in **All FI** (Î” {path['AllFI_delta']:+,.0f}) "
                            f"is primarily from **{path['Sector']}** (Î” {path['Sector_delta']:+,.0f}), "
                            f"specifically **{path.get('Subsector','-')}** â€” "
                            f"**{path.get('Institution','-')}** (Î” {path['Institution_delta']:+,.0f}) at **{period_pick}**."
                        )
                        inst_rows = []
                        for inst, s in agg['Institution'].items():
                            d = _delta_prev(s, period_pick)
                            inst_rows.append((inst, s.get(period_pick, np.nan), d))
                        top_inst = pd.DataFrame(inst_rows, columns=['Institution','Value','Î” from prev']).dropna()
                        top_inst['absÎ”'] = top_inst['Î” from prev'].abs()
                        top_inst = top_inst.sort_values('absÎ”', ascending=False).drop(columns='absÎ”').head(10)
                        st.dataframe(top_inst, use_container_width=True)
                        st.download_button("ðŸ“¥ Download top contributions (CSV)",
                                           top_inst.to_csv(index=False).encode('utf-8'), "attribution.csv",
                                           "text/csv", use_container_width=True)

# Report (batch monthly scan)
with tab4:
    st.markdown("Scan selected datasets (monthly) and export a master outlier report.")
    pick = st.multiselect("Datasets to scan", list(SHEET_MAP.keys()), default=list(SHEET_MAP.keys()))
    if st.button("ðŸš€ Run scan", use_container_width=True):
        master = []
        progress = st.progress(0, text="Scanning...")
        for i, q in enumerate(pick):
            progress.progress(i/max(1,len(pick)), text=f"Scanning: {q}")
            dfc = load_data(current_year, SHEET_MAP[q])
            dfp = load_data(comparison_year, SHEET_MAP[q]) if comparison_year else None
            if isinstance(dfc, str): continue
            rq_q = get_reporting_quarter(current_year)
            months_q = [m for m in ALL_MONTHS[:rq_q*3] if m in dfc.columns]
            for _, r in dfc.iterrows():
                ent = r['Entity / Group']
                wc = r['Worker Category']
                subq = r['Subquestion'] if 'Subquestion' in dfc.columns else 'N/A'
                ser_cur = pd.to_numeric(pd.Series(r[months_q]), errors='coerce').astype(float); ser_cur.index = months_q
                ser_pr = None
                if isinstance(dfp, pd.DataFrame):
                    rr = dfp[(dfp['Entity / Group']==ent) & (dfp['Worker Category']==wc)]
                    if 'Subquestion' in dfp.columns: rr = rr[rr['Subquestion']==subq]
                    if not rr.empty and all(m in rr.columns for m in months_q):
                        ser_pr = pd.to_numeric(rr[months_q].iloc[0], errors='coerce').astype(float)

                a = score_pillars(
                    ser_cur, ser_pr,
                    mom_pct_thresh=0.25, mom_abs_floor=abs_floor,
                    yoy_pct_thresh=yoy_thresh, iqr_k=iqr_k, view="Monthly"
                )
                flagged = a[a['Label'].isin(["True Outlier","Probable Outlier"])]
                if not flagged.empty:
                    for per, row in flagged.iterrows():
                        master.append([q, ent, subq, wc, per, row['Label'], ", ".join(sorted(set(row['Alerts']))), float(row['Composite']), float(row['Value'])])

        progress.progress(1.0, text="Done")
        if master:
            out = pd.DataFrame(master, columns=['Question','Entity / Group','Subquestion','Worker Category','Period','Label','Alerts','_Composite','Value'])
            out = out.sort_values(['Label','_Composite'], ascending=[True, False]).drop(columns=['_Composite'])
            st.success(f"Found {len(out)} flagged points.")
            st.dataframe(out, use_container_width=True)
            st.download_button("ðŸ“¥ Download master report (CSV)", out.to_csv(index=False).encode('utf-8'),
                               "master_outliers.csv", "text/csv", use_container_width=True)
        else:
            st.info("No flagged outliers under current thresholds.")
