# app.py â€” Engine-driven Attribution + Attribution-based Report (fixed All-FI numeric handling)
import os, re
import numpy as np
import pandas as pd
import streamlit as st
import plotly.graph_objects as go

# =========================
# Page & minimal styling
# =========================
st.set_page_config(page_title="QC Intelligence (Attribution-Driven)", page_icon="ðŸ“Š", layout="wide")
st.markdown("""
<style>
  .stApp { background:#F5F7FB; }
  .kpi-card {
    padding:14px; border-radius:10px; background:#fff; border:1px solid #e7e7e7;
    box-shadow:0 2px 8px rgba(0,0,0,0.03); text-align:center;
  }
  .subtle { color:#666; font-size:0.9rem; }
</style>
""", unsafe_allow_html=True)

# =========================
# Constants
# =========================
ALL_MONTHS = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']
SHEET_MAP = {
    'Q1A: Employees': 'QC_Q1A_Main',
    'Q2A: Salary': 'QC_Q2A_Main',
    'Q3: Hours Worked': 'QC_Q3',
    'Q4: Vacancies': 'QC_Q4',
    'Q5: Separations': 'QC_Q5'
}

# Composite label thresholds (UI shows labels only)
COMPOSITE_LABELS = [
    (0.75, "True Outlier"),
    (0.65, "Probable Outlier"),
    (0.50, "Watchlist"),
]

# Rolling (fixed per your request)
ROLL_W = 3
ROLL_KSIG = 2.5       # 0.6 score threshold
ROLL_KSIG_STRONG = 3.0
ROLL_REL = 0.25       # 25% fallback if stdâ‰ˆ0
ROLL_REL_STRONG = 0.40

# Weights (internal; monthly vs quarterly)
WEIGHTS_MONTHLY   = dict(MoM=0.35, YoY=0.30, IQR=0.20, ROLL=0.15)
WEIGHTS_QUARTERLY = dict(MoM=0.25, YoY=0.40, IQR=0.25, ROLL=0.10)

# =========================
# Loaders
# =========================
@st.cache_data
def load_data(year: int|None, sheet_name: str):
    if year is None:
        return None
    fp = f"submission/qc_workbook_{year}.xlsx"
    if not os.path.exists(fp):
        return f"Error: file not found â†’ {fp}"
    try:
        df = pd.read_excel(fp, sheet_name=sheet_name, header=5)
        df.dropna(axis=1, how='all', inplace=True)
        df.rename(columns={'Q1.1':'Q1_Total','Q2.1':'Q2_Total','Q3.1':'Q3_Total','Q4.1':'Q4_Total'}, inplace=True)
        return df
    except Exception as e:
        return f"Error reading '{sheet_name}' from {fp}: {e}"

@st.cache_data
def get_reporting_quarter(year: int):
    fp = f"submission/qc_workbook_{year}.xlsx"
    try:
        about_df = pd.read_excel(fp, sheet_name="_About", header=None)
        quarter_row = about_df[about_df[0] == 'Quarter']
        if not quarter_row.empty:
            return int(re.search(r'\d+', str(quarter_row.iloc[0, 1])).group())
    except Exception:
        pass
    return 4

@st.cache_data
def load_hierarchy_map(path="submission/entity_hierarchy.csv"):
    if not os.path.exists(path):
        return None, "Hierarchy map not found. Place submission/entity_hierarchy.csv (Institution,Sector,Subsector)."
    try:
        h = pd.read_csv(path)
        req = {'Institution','Sector','Subsector'}
        if not req.issubset(set(h.columns)):
            return None, f"Hierarchy CSV missing columns. Need {req}"
        return h, None
    except Exception as e:
        return None, f"Error reading hierarchy map: {e}"

# =========================
# Helpers
# =========================
def _row_filter(df, entity, worker_cat, subq):
    cond = (df['Entity / Group'] == entity) & (df['Worker Category'] == worker_cat)
    if 'Subquestion' in df.columns:
        cond &= (df['Subquestion'] == subq)
    return df[cond]

def build_quarter_series(data_row, year, reporting_quarter):
    if data_row.empty: return pd.Series(dtype=float)
    labels, vals, have_any = [], [], False
    for q in range(1, reporting_quarter+1):
        col = f'Q{q}_Total'
        if col in data_row.columns:
            v = pd.to_numeric(data_row.iloc[0][col], errors='coerce')
            if not pd.isna(v):
                have_any = True; labels.append(f"Q{q} {year}"); vals.append(float(v))
    if not have_any or len(labels) < reporting_quarter:
        q_map = {1: ALL_MONTHS[0:3], 2: ALL_MONTHS[3:6], 3: ALL_MONTHS[6:9], 4: ALL_MONTHS[9:12]}
        present_qs = {int(l.split()[0][1:]) for l in labels}
        for q in range(1, reporting_quarter+1):
            if q in present_qs: continue
            mlist = [m for m in q_map[q] if m in data_row.columns]
            if mlist:
                ser = pd.to_numeric(data_row[mlist].iloc[0], errors='coerce').astype(float)
                if not np.all(np.isnan(ser.values)):
                    labels.append(f"Q{q} {year}"); vals.append(float(np.nansum(ser.values)))
    if not labels: return pd.Series(dtype=float)
    order = np.argsort([int(l.split()[0][1:]) for l in labels])
    labels = [labels[i] for i in order]; vals = [vals[i] for i in order]
    return pd.Series(vals, index=labels, dtype=float)

def _rolling(series: pd.Series, window=ROLL_W):
    m = series.rolling(window=window, min_periods=max(2, window//2)).mean()
    s = series.rolling(window=window, min_periods=max(2, window//2)).std()
    return m, s

def _weights(view):  # Monthly vs Quarterly
    return WEIGHTS_MONTHLY if view == "Monthly" else WEIGHTS_QUARTERLY

def _compose_label(score: float, consensus_ok: bool):
    if not consensus_ok:
        return ""
    for thr, name in COMPOSITE_LABELS:
        if score >= thr:
            return name
    return ""

def _delta_prev(series, period):
    if period not in series.index: return np.nan
    i = list(series.index).index(period)
    if i == 0: return np.nan
    v, pv = series.iloc[i], series.iloc[i-1]
    if pd.isna(v) or pd.isna(pv): return np.nan
    return v - pv

# =========================
# 4-Pillar Engine (fixed rolling)
# =========================
def score_pillars(series, prior_series, mom_pct_thresh, mom_abs_floor, yoy_pct_thresh, iqr_k, view):
    """
    Returns DataFrame (index=Period):
      Value, RollingMean, Alerts(list), Label(str), Composite(float)
    """
    idx = list(series.index)
    out_rows = []

    # IQR bounds
    valid = series.dropna()
    if len(valid) >= 4:
        q1, q3 = valid.quantile(0.25), valid.quantile(0.75)
        iqr = q3 - q1
        lb, ub = q1 - iqr_k*iqr, q3 + iqr_k*iqr
    else:
        lb = ub = iqr = None

    r_mean, r_std = _rolling(series, ROLL_W)
    W = _weights(view)

    for i, p in enumerate(idx):
        v = series.iloc[i]
        alerts = []
        s_mom = s_yoy = s_iqr = s_roll = 0.0

        # MoM shock
        if i > 0 and not pd.isna(v):
            prev = series.iloc[i-1]
            if not pd.isna(prev) and prev != 0:
                d_abs = v - prev
                d_pct = d_abs / prev
                if abs(d_pct) > mom_pct_thresh and abs(d_abs) > mom_abs_floor:
                    alerts.append("High Volatility (MoM)")
                    s_mom = 1.0 if abs(d_pct) > max(0.5, mom_pct_thresh*2) else 0.6

        # YoY
        if prior_series is not None and p in prior_series.index and not pd.isna(v):
            prev_y = prior_series.loc[p]
            if not pd.isna(prev_y) and prev_y != 0:
                yoy = (v - prev_y) / prev_y
                if abs(yoy) > yoy_pct_thresh:
                    alerts.append("YoY Anomaly")
                    s_yoy = 1.0 if abs(yoy) > max(0.60, yoy_pct_thresh*2) else 0.6

        # IQR
        if lb is not None and not pd.isna(v):
            if v < lb or v > ub:
                alerts.append("IQR Range Break")
                dist = 0.0
                if iqr and iqr != 0:
                    if v > ub: dist = (v - ub)/iqr
                    else: dist = (lb - v)/iqr
                s_iqr = 1.0 if dist >= 1.0 else 0.6

        # Rolling deviation (3M)
        mu = r_mean.iloc[i] if len(r_mean) > i else np.nan
        sd = r_std.iloc[i] if len(r_std) > i else np.nan
        if not pd.isna(v) and not pd.isna(mu):
            if not pd.isna(sd) and sd > 0:
                z = abs(v - mu)/sd
                if z >= ROLL_KSIG_STRONG:
                    alerts.append("Rolling Break (3M)"); s_roll = 1.0
                elif z >= ROLL_KSIG:
                    alerts.append("Rolling Break (3M)"); s_roll = 0.6
            else:
                if mu != 0:
                    rel = abs(v - mu)/abs(mu)
                    if rel >= ROLL_REL_STRONG:
                        alerts.append("Rolling Break (3M)"); s_roll = 1.0
                    elif rel >= ROLL_REL:
                        alerts.append("Rolling Break (3M)"); s_roll = 0.6

        comp = (W['MoM']*s_mom + W['YoY']*s_yoy + W['IQR']*s_iqr + W['ROLL']*s_roll)
        strong = sum(x >= 0.6 for x in [s_mom, s_yoy, s_iqr, s_roll])
        any1 = any(abs(x - 1.0) < 1e-9 for x in [s_mom, s_yoy, s_iqr, s_roll])
        any04 = sum(x >= 0.4 for x in [s_mom, s_yoy, s_iqr, s_roll]) >= 2
        consensus_ok = (strong >= 2) or (any1 and any04)
        label = _compose_label(comp, consensus_ok)

        out_rows.append(dict(
            Period=p, Value=float(v) if not pd.isna(v) else np.nan,
            RollingMean=float(mu) if not pd.isna(mu) else np.nan,
            Alerts=alerts, Label=label, Composite=float(comp)
        ))

    df = pd.DataFrame(out_rows).set_index("Period")
    # Sort: True â†’ Probable â†’ Watchlist â†’ none
    order = {"True Outlier":0, "Probable Outlier":1, "Watchlist":2, "":3}
    return df.assign(_o=df['Label'].map(order)).sort_values(['_o','Composite'], ascending=[True,False]).drop(columns=['_o'])

# =========================
# Plot (with MoM band + 3M rolling)
# =========================
def plot_series(series_cur, series_prior, title):
    x = list(series_cur.index)
    y = series_cur.values.astype(float)
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=x, y=y, mode='lines+markers', name='Current',
                             hovertemplate='Period: %{x}<br>Value: %{y:,.0f}<extra></extra>'))
    if series_prior is not None and not series_prior.empty:
        fig.add_trace(go.Scatter(x=list(series_prior.index),
                                 y=series_prior.values.astype(float),
                                 mode='lines+markers', name='Comparison', line=dict(dash='dash'),
                                 hovertemplate='Period: %{x}<br>Value: %{y:,.0f}<extra></extra>'))
    if len(y) >= 2:
        upper = [None] + [y[i-1]*1.25 for i in range(1, len(y))]
        lower = [None] + [y[i-1]*0.75 for i in range(1, len(y))]
        fig.add_trace(go.Scatter(x=x, y=lower, mode='lines', line=dict(width=0), hoverinfo='skip', showlegend=False))
        fig.add_trace(go.Scatter(x=x, y=upper, mode='lines', line=dict(width=0), fill='tonexty',
                                 name='MoM Â±25% Range', opacity=0.15, hoverinfo='skip'))
        r_mean = pd.Series(y).rolling(window=ROLL_W, min_periods=max(2, ROLL_W//2)).mean().values
        fig.add_trace(go.Scatter(x=x, y=r_mean, mode='lines', name=f'Rolling Mean ({ROLL_W}M)',
                                 line=dict(width=1.5),
                                 hovertemplate='Rolling: %{y:,.0f}<extra></extra>'))
    fig.update_layout(title=title, hovermode='x unified',
                      legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='left', x=0),
                      margin=dict(l=10, r=10, t=50, b=10))
    fig.update_xaxes(tickangle=45)
    st.plotly_chart(fig, use_container_width=True)

# =========================
# Engine-Driven Attribution
# (uses Composite Ã— |Î”| for ranking)
# =========================
def build_allfi_series(slice_df, cols):
    """
    Sum across institutions for the selected columns (months or quarters).
    Returns a Series indexed by cols.
    """
    use_cols = [c for c in cols if c in slice_df.columns]
    if not use_cols or slice_df.empty:
        return pd.Series(dtype=float)
    df_num = slice_df[use_cols].apply(pd.to_numeric, errors='coerce')
    s = df_num.sum(axis=0, skipna=True)
    s = s.reindex(use_cols).astype(float)
    return s

def engine_for_institution_row(row, cols, prior_row, view, abs_floor, yoy_thresh, iqr_k):
    s = pd.to_numeric(row[cols].iloc[0], errors='coerce').astype(float)
    s.index = cols
    prior = None
    if prior_row is not None and not prior_row.empty and all(c in prior_row.columns for c in cols):
        prior = pd.to_numeric(prior_row[cols].iloc[0], errors='coerce').astype(float)
        prior.index = cols
    return score_pillars(s, prior, mom_pct_thresh=0.25, mom_abs_floor=abs_floor,
                         yoy_pct_thresh=yoy_thresh, iqr_k=iqr_k, view=view)

def run_engine_all_institutions(df_cur, df_pr, cols, view, subquestion, worker_cat, abs_floor, yoy_thresh, iqr_k):
    """
    Returns a DF with rows per (Institution, Period) including:
      Value, Î”, Composite, Label, Alerts(list)
    """
    working = df_cur.copy()
    if 'Subquestion' in working.columns:
        working = working[working['Subquestion'] == subquestion]
    working = working[working['Worker Category'] == worker_cat].copy()

    out = []
    for _, r in working.iterrows():
        ent = r['Entity / Group']
        prior_row = None
        if isinstance(df_pr, pd.DataFrame):
            prior_row = df_pr[(df_pr['Entity / Group']==ent) & (df_pr['Worker Category']==worker_cat)]
            if 'Subquestion' in df_cur.columns and 'Subquestion' in df_pr.columns:
                prior_row = prior_row[prior_row['Subquestion']==subquestion]
        scores = engine_for_institution_row(pd.DataFrame([r]), cols, prior_row, view, abs_floor, yoy_thresh, iqr_k)
        if scores.empty: continue
        s_vals = pd.to_numeric(pd.Series(r[cols]), errors='coerce').astype(float); s_vals.index = cols
        for per, row_s in scores.iterrows():
            delta = _delta_prev(s_vals, per)
            out.append({
                'Institution': ent, 'Period': per,
                'Value': row_s['Value'], 'Delta': float(delta) if not pd.isna(delta) else np.nan,
                'Composite': row_s['Composite'], 'Label': row_s['Label'], 'Alerts': row_s['Alerts']
            })
    if not out:
        return pd.DataFrame(columns=['Institution','Period','Value','Delta','Composite','Label','Alerts'])
    df = pd.DataFrame(out)
    return df

def attribute_by_engine(institution_results: pd.DataFrame, hmap: pd.DataFrame, period: str):
    """
    institution_results: rows per institution-period with Composite, Delta, Label, Alerts
    Returns attribution tables ranked by CompositeÃ—|Î”|.
    """
    usable = institution_results[institution_results['Period'] == period].copy()
    if usable.empty:
        return None, None, None
    usable = usable.merge(hmap, on='Institution', how='left')
    usable['AbsDelta'] = usable['Delta'].abs()
    usable['AttribScore'] = usable['Composite'] * usable['AbsDelta']  # <== core attribution score

    sec_rank = usable.groupby('Sector', dropna=True, as_index=False).agg(
        AttribScore=('AttribScore','sum'),
        AvgComposite=('Composite','mean'),
        TotalAbsDelta=('AbsDelta','sum')
    ).sort_values('AttribScore', ascending=False)

    if sec_rank.empty:
        return None, None, None
    sector = sec_rank.iloc[0]['Sector']

    sub_rank = usable[usable['Sector'] == sector].groupby('Subsector', as_index=False).agg(
        AttribScore=('AttribScore','sum'),
        AvgComposite=('Composite','mean'),
        TotalAbsDelta=('AbsDelta','sum')
    ).sort_values('AttribScore', ascending=False)

    subsector = sub_rank.iloc[0]['Subsector'] if not sub_rank.empty else None

    if subsector is not None:
        inst_rank = usable[(usable['Sector']==sector) & (usable['Subsector']==subsector)].copy()
    else:
        inst_rank = usable[usable['Sector']==sector].copy()
    inst_rank = inst_rank.groupby(['Institution'], as_index=False).agg(
        AttribScore=('AttribScore','sum'),
        Composite=('Composite','max'),
        Delta=('Delta','sum'),
        Alerts=('Alerts', lambda L: ", ".join(sorted(set([a for sub in L for a in (sub if isinstance(sub, list) else [])]))))
    ).sort_values('AttribScore', ascending=False)

    return sec_rank, sub_rank, inst_rank

# =========================
# Sidebar controls
# =========================
st.sidebar.title("Controls")
current_year = st.sidebar.selectbox("Current Year", [2026, 2025, 2024, 2023], index=1)
comparison_year = st.sidebar.selectbox("Comparison Year", [2025, 2024, 2023, None], index=0)
dataset = st.sidebar.selectbox("Dataset", list(SHEET_MAP.keys()))
time_view = st.sidebar.radio("Timeframe", ['Monthly','Quarterly'], horizontal=True)

st.sidebar.markdown("---")
abs_floor = st.sidebar.slider("Absolute Change floor", 10, 1000, 50, 10)
iqr_k = st.sidebar.slider("IQR Sensitivity (k)", 1.0, 3.0, 1.5, 0.1)
yoy_pct = st.sidebar.slider("YoY % Threshold", 0, 100, 30, 5, format="%d%%")
yoy_thresh = yoy_pct / 100.0

st.sidebar.markdown("---")
multi_year = st.sidebar.checkbox("Enable Multi-Year Monthly View", value=False)
start_year = st.sidebar.selectbox("Start Year", [2021, 2022, 2023, 2024, 2025, 2026], index=0, disabled=not multi_year)

# =========================
# Load data & selections
# =========================
sheet_name = SHEET_MAP[dataset]
df_current = load_data(current_year, sheet_name)
df_prior   = load_data(comparison_year, sheet_name) if comparison_year else None
if isinstance(df_current, str):
    st.error(df_current); st.stop()

rq = get_reporting_quarter(current_year)
months_to_analyze = [m for m in ALL_MONTHS[:rq*3] if m in df_current.columns]

entity = st.selectbox("Entity / Group", options=df_current['Entity / Group'].unique())
if 'Subquestion' in df_current.columns and df_current[df_current['Entity / Group']==entity]['Subquestion'].nunique() > 1:
    subquestion = st.selectbox("Subquestion", options=df_current[df_current['Entity / Group']==entity]['Subquestion'].unique())
    worker_cat = st.selectbox("Worker Category", options=df_current[(df_current['Entity / Group']==entity) & (df_current['Subquestion']==subquestion)]['Worker Category'].unique())
    row_cur = _row_filter(df_current, entity, worker_cat, subquestion)
else:
    subquestion = "N/A"
    worker_cat = st.selectbox("Worker Category", options=df_current[df_current['Entity / Group'] == entity]['Worker Category'].unique())
    row_cur = _row_filter(df_current, entity, worker_cat, subquestion)

row_prior = None
if not isinstance(df_prior, str) and df_prior is not None:
    row_prior = _row_filter(df_prior, entity, worker_cat, subquestion)

# =========================
# Build series for Explore/Anomalies
# =========================
def build_monthly_series_single_year(row, months):
    if row.empty or not months:
        return pd.Series(dtype=float)
    s = pd.to_numeric(row[months].iloc[0], errors='coerce').astype(float)
    s.index = months
    return s

def build_monthly_series_multi_year(entity_name, worker_cat, subq, sheet_name, start_year, end_year):
    vals, idx = [], []
    for yr in range(start_year, end_year+1):
        d = load_data(yr, sheet_name)
        if isinstance(d, str) or d is None: continue
        r = d[(d['Entity / Group']==entity_name) & (d['Worker Category']==worker_cat)]
        if 'Subquestion' in d.columns:
            r = r[r['Subquestion']==subq]
        if r.empty: continue
        rqy = get_reporting_quarter(yr)
        months_y = [m for m in ALL_MONTHS[:rqy*3] if m in r.columns]
        if not months_y: continue
        sy = pd.to_numeric(r[months_y].iloc[0], errors='coerce').astype(float)
        vals.extend(list(sy.values))
        idx.extend([f"{yr}-{m}" for m in months_y])
    if not idx: return pd.Series(dtype=float)
    return pd.Series(vals, index=idx, dtype=float)

# Build selected series
if time_view == 'Monthly':
    if multi_year:
        series_cur = build_monthly_series_multi_year(entity, worker_cat, subquestion, sheet_name, start_year, current_year)
        series_prior = None
    else:
        series_cur = build_monthly_series_single_year(row_cur, months_to_analyze)
        series_prior = build_monthly_series_single_year(row_prior, months_to_analyze) if row_prior is not None and not row_prior.empty else None
else:
    series_cur = build_quarter_series(row_cur, current_year, rq)
    series_prior = build_quarter_series(row_prior, comparison_year, get_reporting_quarter(comparison_year)) if (row_prior is not None and not row_prior.empty and comparison_year) else None

# =========================
# KPI Header
# =========================
st.markdown("### QC Intelligence (Attribution-Driven)")
c1, c2, c3, c4 = st.columns(4)
with c1: st.markdown(f"<div class='kpi-card'><div class='subtle'>Current Year</div><h3>{current_year}</h3></div>", unsafe_allow_html=True)
with c2: st.markdown(f"<div class='kpi-card'><div class='subtle'>Timeframe</div><h3>{time_view}{' â€¢ Multi-Year' if (time_view=='Monthly' and multi_year) else ''}</h3></div>", unsafe_allow_html=True)
with c3: st.markdown(f"<div class='kpi-card'><div class='subtle'>Dataset</div><h3>{dataset}</h3></div>", unsafe_allow_html=True)
with c4:
    latest_val = series_cur.iloc[-1] if not series_cur.empty else np.nan
    st.markdown(f"<div class='kpi-card'><div class='subtle'>Latest Value</div><h3>{latest_val:,.0f}</h3></div>", unsafe_allow_html=True)

# =========================
# Tabs
# =========================
tab1, tab2, tab3, tab4 = st.tabs(["ðŸ”Ž Explore", "ðŸš¨ Anomalies", "ðŸ§­ Attribution", "ðŸ§¾ Report"])

# ---- Explore
with tab1:
    if series_cur.empty or series_cur.isnull().all():
        st.warning("No data for selected filters/period.")
    else:
        title = f"{'Monthly' if time_view=='Monthly' else 'Quarterly'} â€” {entity} | {worker_cat}"
        plot_series(series_cur, series_prior, title)

# ---- Anomalies (per selected entity)
with tab2:
    if series_cur.empty or series_cur.isnull().all():
        st.info("No data to analyze.")
    else:
        a = score_pillars(series_cur, series_prior,
                          mom_pct_thresh=0.25, mom_abs_floor=abs_floor,
                          yoy_pct_thresh=yoy_thresh, iqr_k=iqr_k, view=time_view)
        show = a.copy()
        show['Alerts'] = show['Alerts'].apply(lambda L: ", ".join(sorted(set(L))))
        st.markdown("**Alerts (sorted by severity):**")
        st.dataframe(show[['Value','RollingMean','Alerts','Label']].style.format({'Value':'{:,.0f}','RollingMean':'{:,.0f}'}), use_container_width=True)

# ---- Attribution (ENGINE-DRIVEN)
with tab3:
    hmap, herr = load_hierarchy_map()
    if herr:
        st.info(herr)
    else:
        # Choose columns for aggregation (months or quarters)
        if time_view == 'Monthly' and multi_year:
            cols = list(series_cur.index)
            st.caption("Attribution in Multi-Year mode uses long-run monthly labels (YoY pillar suppressed).")
            st.info("For heavy datasets, prefer Single-Year attribution. Multi-Year attribution can be added similarly if needed.")
        else:
            if time_view == 'Monthly':
                cols = months_to_analyze
            else:
                cols = list(series_cur.index)

        if time_view == 'Monthly' and not months_to_analyze and not multi_year:
            st.warning("No months available.")
        else:
            slice_df = df_current.copy()
            if 'Subquestion' in slice_df.columns:
                slice_df = slice_df[slice_df['Subquestion'] == subquestion]
            slice_df = slice_df[slice_df['Worker Category'] == worker_cat].copy()

            if time_view == 'Monthly' and not multi_year:
                allfi_cur = build_allfi_series(slice_df, cols)
                allfi_prior = None
                if isinstance(df_prior, pd.DataFrame):
                    slice_pr = df_prior.copy()
                    if 'Subquestion' in slice_pr.columns:
                        slice_pr = slice_pr[slice_pr['Subquestion'] == subquestion]
                    slice_pr = slice_pr[slice_pr['Worker Category'] == worker_cat]
                    use_cols = [c for c in cols if c in slice_pr.columns]
                    if not slice_pr.empty and use_cols:
                        df_num_pr = slice_pr[use_cols].apply(pd.to_numeric, errors='coerce')
                        allfi_prior = df_num_pr.sum(axis=0, skipna=True).reindex(use_cols).astype(float)
                allfi_anom = score_pillars(allfi_cur, allfi_prior,
                                           mom_pct_thresh=0.25, mom_abs_floor=abs_floor,
                                           yoy_pct_thresh=yoy_thresh, iqr_k=iqr_k, view=time_view)
            else:
                allfi_anom = None

            if allfi_anom is not None:
                critical = allfi_anom[allfi_anom['Label'] == "True Outlier"]
                if critical.empty:
                    st.info("No All FI True Outliers under current thresholds â€” select a period from your entity to attribute.")
                    period_pick = st.selectbox("Pick a period to explain", list(series_cur.index))
                else:
                    period_pick = st.selectbox("Pick a period (All FI True Outlier) to explain", list(critical.index))
            else:
                period_pick = st.selectbox("Pick a period to explain", list(series_cur.index))

            if time_view == 'Monthly' and multi_year:
                st.warning("Multi-Year attribution is heavy; this demo focuses attribution on Single-Year mode for performance. Use Report to see attribution results at scale.")
            else:
                inst_results = run_engine_all_institutions(df_current, df_prior, cols, time_view, subquestion, worker_cat, abs_floor, yoy_thresh, iqr_k)
                if inst_results.empty:
                    st.info("No institution-level results to attribute.")
                else:
                    sec_rank, sub_rank, inst_rank = attribute_by_engine(inst_results, hmap, period_pick)
                    if sec_rank is None:
                        st.info("Not enough data to compute attribution for that period.")
                    else:
                        top_sec = sec_rank.iloc[0]
                        top_sub = sub_rank.iloc[0] if sub_rank is not None and not sub_rank.empty else None
                        top_inst = inst_rank.iloc[0] if inst_rank is not None and not inst_rank.empty else None
                        st.markdown(
                            f"**Attribution (Engine-Driven):** In **{period_pick}**, "
                            f"top sector is **{top_sec['Sector']}** (AttribScore {top_sec['AttribScore']:,.0f}), "
                            f"{'subsector **'+str(top_sub['Subsector'])+'** (AttribScore '+format(top_sub['AttribScore'],',.0f')+'), ' if top_sub is not None else ''}"
                            f"institution **{top_inst['Institution']}** (AttribScore {top_inst['AttribScore']:,.0f}, "
                            f"Composite {top_inst['Composite']:.2f}, Î” {top_inst['Delta']:+,.0f})."
                        )
                        st.subheader("Sectors (ranked by Composite Ã— |Î”|)")
                        st.dataframe(sec_rank, use_container_width=True)
                        st.subheader("Subsectors (within top sector)")
                        st.dataframe(sub_rank, use_container_width=True)
                        st.subheader("Institutions (within chosen subsector/sector)")
                        st.dataframe(inst_rank, use_container_width=True)

# ---- Report (Attribution-based export)
with tab4:
    st.markdown("Generate a **final report** where each line is an attribution result (engine-driven).")
    detection_mode = st.radio("Detection Mode:", ["Single-Year QC (Short-Term)", "Multi-Year Continuous (Long-Term)"], horizontal=True)
    pick = st.multiselect("Datasets to include", list(SHEET_MAP.keys()), default=list(SHEET_MAP.keys()))
    start_multi = st.number_input("Start Year (for Multi-Year mode)", min_value=2018, max_value=current_year, value=2021, step=1, disabled=(detection_mode!="Multi-Year Continuous (Long-Term)"))
    if st.button("ðŸš€ Generate Attribution Report", use_container_width=True):
        hmap, herr = load_hierarchy_map()
        if herr:
            st.error(herr); st.stop()

        records = []
        for qname in pick:
            sheet = SHEET_MAP[qname]
            dfc = load_data(current_year, sheet)
            dfp = load_data(comparison_year, sheet) if comparison_year and detection_mode=="Single-Year QC (Short-Term)" else None
            if isinstance(dfc, str) or dfc is None: continue

            if detection_mode == "Single-Year QC (Short-Term)":
                rq_y = get_reporting_quarter(current_year)
                cols = [m for m in ALL_MONTHS[:rq_y*3] if m in dfc.columns]
                wc_list = sorted(dfc['Worker Category'].dropna().unique())
                subq_list = sorted(dfc['Subquestion'].dropna().unique()) if 'Subquestion' in dfc.columns else ['N/A']
                for wc in wc_list:
                    for subq in subq_list:
                        slice_c = dfc[dfc['Worker Category']==wc].copy()
                        if 'Subquestion' in dfc.columns:
                            slice_c = slice_c[slice_c['Subquestion']==subq]
                        if slice_c.empty or not cols: continue

                        allfi_cur = build_allfi_series(slice_c, cols)
                        allfi_pr = None
                        if isinstance(dfp, pd.DataFrame):
                            slice_p = dfp[dfp['Worker Category']==wc].copy()
                            if 'Subquestion' in dfp.columns:
                                slice_p = slice_p[slice_p['Subquestion']==subq]
                            use_cols = [c for c in cols if c in slice_p.columns]
                            if not slice_p.empty and use_cols:
                                df_num_pr = slice_p[use_cols].apply(pd.to_numeric, errors='coerce')
                                allfi_pr = df_num_pr.sum(axis=0, skipna=True).reindex(use_cols).astype(float)

                        allfi_anom = score_pillars(allfi_cur, allfi_pr, 0.25, abs_floor, yoy_thresh, iqr_k, "Monthly")
                        flagged_periods = allfi_anom[allfi_anom['Label'].isin(["True Outlier","Probable Outlier"])].index.tolist()
                        if not flagged_periods: continue

                        inst_results = run_engine_all_institutions(dfc, dfp, cols, "Monthly", subq, wc, abs_floor, yoy_thresh, iqr_k)
                        if inst_results.empty: continue

                        for per in flagged_periods:
                            sec_rank, sub_rank, inst_rank = attribute_by_engine(inst_results, hmap, per)
                            if sec_rank is None or sub_rank is None or inst_rank is None or inst_rank.empty: continue
                            s1 = sec_rank.iloc[0]; s2 = sub_rank.iloc[0]; s3 = inst_rank.iloc[0]
                            records.append({
                                "Mode": "Single-Year",
                                "Dataset": qname,
                                "Worker Category": wc,
                                "Subquestion": subq,
                                "Period": per,
                                "Sector": s1['Sector'],
                                "Sector AttribScore": s1['AttribScore'],
                                "Subsector": s2['Subsector'],
                                "Subsector AttribScore": s2['AttribScore'],
                                "Institution": s3['Institution'],
                                "Institution AttribScore": s3['AttribScore'],
                                "Institution Composite": s3['Composite'],
                                "Institution Î”": s3['Delta'],
                                "Institution Alerts": s3['Alerts'],
                            })

            else:
                years = [y for y in range(int(start_multi), current_year+1)]
                wc_list = sorted(dfc['Worker Category'].dropna().unique())
                subq_list = sorted(dfc['Subquestion'].dropna().unique()) if 'Subquestion' in dfc.columns else ['N/A']
                for wc in wc_list:
                    for subq in subq_list:
                        inst_series_map = {}
                        for _, r in dfc[dfc['Worker Category']==wc].iterrows():
                            if 'Subquestion' in dfc.columns and r.get('Subquestion', subq) != subq:
                                continue
                            inst = r['Entity / Group']
                            vals, idx = [], []
                            for yr in years:
                                d = load_data(yr, sheet)
                                if isinstance(d, str) or d is None: continue
                                rr = d[(d['Entity / Group']==inst) & (d['Worker Category']==wc)]
                                if 'Subquestion' in d.columns:
                                    rr = rr[rr['Subquestion']==subq]
                                if rr.empty: continue
                                rqy = get_reporting_quarter(yr)
                                months_y = [m for m in ALL_MONTHS[:rqy*3] if m in rr.columns]
                                if not months_y: continue
                                sy = pd.to_numeric(rr[months_y].iloc[0], errors='coerce').astype(float)
                                vals.extend(list(sy.values))
                                idx.extend([f"{yr}-{m}" for m in months_y])
                            if not idx: continue
                            inst_series_map[inst] = pd.Series(vals, index=idx, dtype=float)
                        if not inst_series_map:
                            continue

                        long_results = []
                        for inst, s in inst_series_map.items():
                            sc = score_pillars(s, prior_series=None, mom_pct_thresh=0.25, mom_abs_floor=abs_floor,
                                               yoy_pct_thresh=1.0, iqr_k=iqr_k, view="Monthly")  # YoY suppressed
                            if sc.empty: continue
                            for per, rowx in sc.iterrows():
                                i = list(s.index).index(per)
                                delta = s.iloc[i] - (s.iloc[i-1] if i>0 else np.nan)
                                long_results.append({
                                    'Institution': inst, 'Period': per, 'Value': rowx['Value'],
                                    'Delta': float(delta) if not pd.isna(delta) else np.nan,
                                    'Composite': rowx['Composite'], 'Label': rowx['Label'], 'Alerts': rowx['Alerts']
                                })
                        if not long_results:
                            continue
                        inst_df = pd.DataFrame(long_results)
                        flagged_periods = inst_df[inst_df['Label'].isin(["True Outlier","Probable Outlier"])]['Period'].unique().tolist()
                        if not flagged_periods:
                            continue
                        for per in flagged_periods:
                            sec_rank, sub_rank, inst_rank = attribute_by_engine(inst_df, hmap, per)
                            if sec_rank is None or sub_rank is None or inst_rank is None or inst_rank.empty: continue
                            s1, s2, s3 = sec_rank.iloc[0], sub_rank.iloc[0], inst_rank.iloc[0]
                            records.append({
                                "Mode": "Multi-Year",
                                "Dataset": qname,
                                "Worker Category": wc,
                                "Subquestion": subq,
                                "Period": per,
                                "Sector": s1['Sector'],
                                "Sector AttribScore": s1['AttribScore'],
                                "Subsector": s2['Subsector'],
                                "Subsector AttribScore": s2['AttribScore'],
                                "Institution": s3['Institution'],
                                "Institution AttribScore": s3['AttribScore'],
                                "Institution Composite": s3['Composite'],
                                "Institution Î”": s3['Delta'],
                                "Institution Alerts": s3['Alerts'],
                            })

        if not records:
            st.info("No attribution-based anomalies found under current settings.")
        else:
            out = pd.DataFrame(records)
            cols = ["Mode","Dataset","Worker Category","Subquestion","Period",
                    "Sector","Sector AttribScore","Subsector","Subsector AttribScore",
                    "Institution","Institution AttribScore","Institution Composite","Institution Î”","Institution Alerts"]
            out = out[cols].sort_values(["Mode","Dataset","Period","Sector AttribScore"], ascending=[True, True, True, False])
            st.success(f"Generated {len(out)} attribution rows.")
            st.dataframe(out, use_container_width=True)
            st.download_button("ðŸ“¥ Download Attribution Report (CSV)", out.to_csv(index=False).encode('utf-8'),
                               "attribution_report.csv", "text/csv", use_container_width=True)
