#!/usr/bin/env python3
from __future__ import annotations
import sys
from pathlib import Path
from typing import List, Dict, Tuple, Optional

import numpy as np
import pandas as pd
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
from openpyxl.worksheet.table import Table, TableStyleInfo

# Reuse your qc_common styling and month/quarter utilities
from qc_common import (
    MONTHS_FULL, Q_TO_MONTHS, QMAP,
    new_empty_workbook, append_about_sheet_last,
    FILL_HEADER, FILL_INFO, FILL_Q1, FILL_Q2, FILL_Q3, FILL_Q4, FILL_RED, FILL_YEL,
    BTHIN
)

# ---------- Config ----------
QC_SHEETS = [
    "QC_Q1A_Main",
    "QC_Q1A_JobFunc_Q4",
    "QC_Q1B",
    "QC_Q2A_Main",
    "QC_Q2A_JobFunc_Q4",
    "QC_Q2B",
    "QC_Q3",
    "QC_Q4",
    "QC_Q5",
]

# Level definitions
GROUP_LABELS = {
    "All Financial Institutions",
    "Banking Institutions",
    "DFI",
    "International Islamic Banks",
    "Insurers",
    "Takaful Operators",
}

SUBGROUP_LABELS = {
    "Commercial Banks",
    "Investment Banks",
    "Islamic Banks",
    "Foreign Banks",
    "Digital Banks",
    "International Islamic Banks",
    "DFI",
    "Insurers",
    "Takaful Operators",
}

# Statistical thresholds (tune here or add CLI later)
Z_THRESHOLD = 3.0        # |z| >= 3
MZ_THRESHOLD = 3.5       # |modified z| >= 3.5
IQR_K = 1.5              # outside [Q1 - k*IQR, Q3 + k*IQR]

# ---------- Helpers ----------
def _load_qc_sheet(xlsx: Path, name: str) -> pd.DataFrame:
    try:
        return pd.read_excel(xlsx, sheet_name=name, engine="openpyxl")
    except Exception:
        return pd.DataFrame()

def _is_jobfunc_sheet(df: pd.DataFrame) -> bool:
    return "Job Function" in df.columns or "job_function" in df.columns

def _detect_numeric_columns(df: pd.DataFrame) -> List[str]:
    """Pick the numeric trend columns we’ll evaluate:
       - Months present (Jan..Dec)
       - Quarter sums (Q1..Q4) if present
       - MoM columns (start 'MoM ')
       - QoQ % columns (start '%Diff ')
       - YoY columns (start 'YoY ')
    """
    cols = []
    # Months
    cols += [m for m in MONTHS_FULL if m in df.columns]
    # Quarters
    cols += [q for q in ["Q1","Q2","Q3","Q4"] if q in df.columns]
    # MoM %
    cols += [c for c in df.columns if isinstance(c, str) and c.startswith("MoM ")]
    # QoQ %
    cols += [c for c in df.columns if isinstance(c, str) and c.startswith("%Diff ")]
    # YoY %
    cols += [c for c in df.columns if isinstance(c, str) and c.startswith("YoY ")]
    # Keep only numeric-convertible
    out = []
    for c in cols:
        s = pd.to_numeric(df[c], errors="coerce")
        if s.notna().any():
            out.append(c)
    return out

def _coerce_numeric_inplace(df: pd.DataFrame, cols: List[str]) -> None:
    for c in cols:
        df[c] = pd.to_numeric(df[c], errors="coerce")

def _cohort_keys(df: pd.DataFrame) -> List[str]:
    # comparable cohort = same subquestion/worker category/(job function if present)
    keys = []
    if "Subquestion" in df.columns: keys.append("Subquestion")
    if "Worker Category" in df.columns: keys.append("Worker Category")
    if "Job Function" in df.columns: keys.append("Job Function")
    return keys

def _stat_block(series: pd.Series) -> Tuple[pd.Series, pd.Series, pd.Series]:
    """Return (z, modified_z, iqr_flag) for a vector."""
    x = series.astype(float)
    # Z
    mu = np.nanmean(x)
    sd = np.nanstd(x, ddof=1)  # sample std
    if sd and sd > 0:
        z = (x - mu) / sd
    else:
        z = pd.Series(np.zeros(len(x)), index=x.index)

    # Modified Z (scaled MAD)
    med = np.nanmedian(x)
    mad = np.nanmedian(np.abs(x - med))
    if mad and mad > 0:
        mz = 0.6745 * (x - med) / mad
    else:
        mz = pd.Series(np.zeros(len(x)), index=x.index)

    # IQR flag
    q1 = np.nanpercentile(x, 25)
    q3 = np.nanpercentile(x, 75)
    iqr = q3 - q1
    if iqr and iqr > 0:
        lo = q1 - IQR_K * iqr
        hi = q3 + IQR_K * iqr
        iqr_flag = (x < lo) | (x > hi)
    else:
        iqr_flag = pd.Series([False]*len(x), index=x.index)

    return (pd.Series(z, index=series.index),
            pd.Series(mz, index=series.index),
            pd.Series(iqr_flag, index=series.index))

def _compute_stats_by_cohort(df: pd.DataFrame, value_cols: List[str]) -> pd.DataFrame:
    """Compute stats across rows for each column within (Subq, WC, JobF) cohorts."""
    work = df.copy()
    keys = _cohort_keys(work)
    for c in value_cols:
        z_col  = f"Z[{c}]"
        mz_col = f"MZ[{c}]"
        iq_col = f"IQR_Flag[{c}]"
        work[z_col] = np.nan
        work[mz_col] = np.nan
        work[iq_col] = False

    if not keys:
        groups = [(None, work.index)]
    else:
        groups = list(work.groupby(keys).groups.items())

    for _, idx in groups:
        block = work.loc[idx]
        for c in value_cols:
            z, mz, iq = _stat_block(block[c])
            work.loc[idx, f"Z[{c}]"] = z.values
            work.loc[idx, f"MZ[{c}]"] = mz.values
            work.loc[idx, f"IQR_Flag[{c}]"] = iq.values

    # Aggregate overall flags
    z_hits  = (work[[f"Z[{c}]" for c in value_cols]].abs() >= Z_THRESHOLD).any(axis=1)
    mz_hits = (work[[f"MZ[{c}]" for c in value_cols]].abs() >= MZ_THRESHOLD).any(axis=1)
    iq_hits = (work[[f"IQR_Flag[{c}]" for c in value_cols]].astype(bool)).any(axis=1)
    work["True_Outlier"] = z_hits | mz_hits | iq_hits

    # Which columns triggered
    reasons = []
    for i, row in work.iterrows():
        cols = []
        for c in value_cols:
            if abs(row.get(f"Z[{c}]", 0)) >= Z_THRESHOLD: cols.append(f"Z:{c}")
            if abs(row.get(f"MZ[{c}]", 0)) >= MZ_THRESHOLD: cols.append(f"MZ:{c}")
            if bool(row.get(f"IQR_Flag[{c}]", False)): cols.append(f"IQR:{c}")
        reasons.append(", ".join(cols))
    work["Outlier_Cols"] = reasons
    return work

# ---------- Styling & writing ----------
def _q_fill_for_month(m: str) -> PatternFill:
    if m in Q_TO_MONTHS["Q1"]: return FILL_Q1
    if m in Q_TO_MONTHS["Q2"]: return FILL_Q2
    if m in Q_TO_MONTHS["Q3"]: return FILL_Q3
    if m in Q_TO_MONTHS["Q4"]: return FILL_Q4
    return FILL_HEADER

def _write_sheet(wb: Workbook, title: str, df: pd.DataFrame) -> None:
    ws = wb.create_sheet(title)
    if df.empty:
        ws["A1"] = f"{title} (no data)"; ws["A1"].font = Font(bold=True)
        return

    # Info band (light)
    ws["A1"] = title; ws["A1"].font = Font(bold=True, size=13)
    for rng in ("A1:A1",):
        for row in ws[rng]:
            for c in row:
                c.fill = FILL_INFO
                c.border = BTHIN

    # We’ll add a band row (quarters) and a header row with real column names
    info_rows = 2
    band_row = info_rows + 1
    header_row = info_rows + 2

    # Ensure column order (dims first)
    cols = list(df.columns)

    # Write band row placeholder
    ws.append([])

    # Write header row
    ws.append(cols)
    for j, h in enumerate(cols, start=1):
        c = ws.cell(header_row, j, h)
        c.font = Font(bold=True)
        c.alignment = Alignment(horizontal="center", vertical="center")
        c.fill = FILL_HEADER
        c.border = BTHIN

    # Quarter band over month columns (no merge)
    for m in [c for c in cols if c in MONTHS_FULL]:
        j = cols.index(m) + 1
        ws.cell(band_row, j).value = next(q for q, ml in Q_TO_MONTHS.items() if m in ml)
        ws.cell(band_row, j).alignment = Alignment(horizontal="center", vertical="center")
        ws.cell(band_row, j).fill = _q_fill_for_month(m)
        ws.cell(band_row, j).border = BTHIN

    # Write data
    first_data_row = header_row + 1
    for _, r in df.iterrows():
        ws.append([r.get(c, "") for c in cols])
    last_data_row = first_data_row + len(df) - 1

    # Freeze panes after dims (Entity / Group is col 1)
    ws.freeze_panes = ws.cell(first_data_row, 2)

    # Apply table (for filters)
    if last_data_row >= first_data_row:
        table_ref = f"A{header_row}:{ws.cell(last_data_row, len(cols)).coordinate}"
        tbl = Table(displayName=title.replace(" ","_"), ref=table_ref)
        tbl.tableStyleInfo = TableStyleInfo(name="TableStyleLight9", showRowStripes=True)
        ws.add_table(tbl)

    # Number formats for numeric columns
    for j, h in enumerate(cols, start=1):
        # percentage-ish columns
        if isinstance(h, str) and (h.startswith("MoM ") or h.startswith("%Diff ") or h.startswith("YoY ") or h.startswith("Z[") or h.startswith("MZ[")):
            fmt = "0.0%"
            # Z and MZ are not percentages
            if h.startswith("Z[") or h.startswith("MZ["):
                fmt = "0.00"
        elif h in MONTHS_FULL or h in ("Q1","Q2","Q3","Q4"):
            fmt = "#,##0"
        elif isinstance(h, str) and h.startswith("Diff "):
            fmt = "#,##0"
        elif h.startswith("IQR_Flag["):
            fmt = "General"
        elif h in ("True_Outlier", "Outlier_Cols"):
            fmt = "General"
        else:
            fmt = "General"
        for r in range(first_data_row, last_data_row + 1):
            ws.cell(r, j).number_format = fmt

    # Auto width
    for j in range(1, len(cols) + 1):
        maxw = max(len(str(ws.cell(header_row, j).value or "")), 10)
        for r in range(first_data_row, min(first_data_row + 50, last_data_row + 1)):
            v = ws.cell(r, j).value
            if v is not None:
                maxw = max(maxw, len(str(v)))
        ws.column_dimensions[ws.cell(1, j).column_letter].width = min(maxw + 2, 28)

# ---------- Main processing ----------
def _split_level(df: pd.DataFrame, level: str) -> pd.DataFrame:
    """Filter df by requested level."""
    if "Entity / Group" not in df.columns:
        return pd.DataFrame()
    eg = df["Entity / Group"].astype(str)

    if level == "GROUP":
        mask = eg.isin(GROUP_LABELS)
        return df.loc[mask].reset_index(drop=True)
    elif level == "SUBGROUP":
        mask = eg.isin(SUBGROUP_LABELS)
        return df.loc[mask].reset_index(drop=True)
    elif level == "ENTITY":
        mask = ~(eg.isin(GROUP_LABELS) | eg.isin(SUBGROUP_LABELS))
        return df.loc[mask].reset_index(drop=True)
    else:
        return pd.DataFrame()

def _prep_inputs(df: pd.DataFrame) -> pd.DataFrame:
    """Normalize columns and types, keep expected dims."""
    if df.empty:
        return df
    work = df.copy()

    # Standardize dimension headers if needed
    rename_map = {}
    if "Subquestion" not in work.columns and "subquestion" in work.columns:
        rename_map["subquestion"] = "Subquestion"
    if "Worker Category" not in work.columns and "worker_category" in work.columns:
        rename_map["worker_category"] = "Worker Category"
    if "Job Function" not in work.columns and "job_function" in work.columns:
        rename_map["job_function"] = "Job Function"
    if rename_map:
        work = work.rename(columns=rename_map)

    # Ensure dim columns exist
    for c in ["Entity / Group","Subquestion","Worker Category","Job Function"]:
        if c not in work.columns:
            work[c] = ""

    # Coerce N/A to NaN (for numeric columns we’ll choose)
    # (actual coercion is applied later on selected numeric cols)
    return work

def _process_one(qc_path: Path, sheet: str, wb_out: Workbook) -> None:
    raw = _load_qc_sheet(qc_path, sheet)
    if raw.empty:
        return

    base = _prep_inputs(raw)

    # Numeric columns to analyze
    value_cols = _detect_numeric_columns(base)
    _coerce_numeric_inplace(base, value_cols)

    # For each level: filter, compute stats, write
    for level in ("GROUP","SUBGROUP","ENTITY"):
        df_level = _split_level(base, level)
        if df_level.empty:
            continue

        df_stats = _compute_stats_by_cohort(df_level, value_cols)

        # Order columns: dims first, then original numeric, then stats and flags
        dim_cols = ["Entity / Group","Subquestion","Worker Category"]
        if "Job Function" in df_stats.columns and df_stats["Job Function"].notna().any():
            dim_cols.append("Job Function")

        stats_cols = [c for c in df_stats.columns if c.startswith("Z[") or c.startswith("MZ[") or c.startswith("IQR_Flag[")]
        aux_cols = ["True_Outlier","Outlier_Cols"]

        # Keep all original columns (so analysts still see MoM/QoQ/YoY/quarters etc.)
        orig_cols = [c for c in base.columns if c not in dim_cols]
        ordered = dim_cols + orig_cols + stats_cols + aux_cols
        ordered = [c for c in ordered if c in df_stats.columns]

        out_title = f"STAT_{sheet}_{level}"
        _write_sheet(wb_out, out_title, df_stats[ordered])

def build_stats_workbook(qc_workbook: Path, out_path: Path) -> None:
    wb = new_empty_workbook()

    any_written = False
    for sheet in QC_SHEETS:
        _process_one(qc_workbook, sheet, wb)
        any_written = True

    if not any_written:
        print("[WARN] No QC sheets found. Nothing to write.")
        return

    # About last
    append_about_sheet_last(wb, "RLMS – Statistical Validation (All Levels)", year=datetime_now_year(), qlabel="—")
    out_path.parent.mkdir(parents=True, exist_ok=True)
    wb.save(out_path)
    print(f"[DONE] {out_path}")

def datetime_now_year() -> int:
    from datetime import datetime
    return datetime.now().year

# ---------- CLI ----------
def main() -> int:
    if len(sys.argv) < 2:
        print("Usage: python qc_stats.py <QC_WORKBOOK.xlsx> [OUTPUT.xlsx]")
        print("Example: python qc_stats.py qc_workbook_2026.xlsx STAT_qc_workbook_2026.xlsx")
        return 2
    qc_path = Path(sys.argv[1])
    out_path = Path(sys.argv[2]) if len(sys.argv) >= 3 else qc_path.with_name(f"STAT_{qc_path.name}")
    build_stats_workbook(qc_path, out_path)
    return 0

if __name__ == "__main__":
    sys.exit(main())
