# extract_q2_staging_turbo.py
from __future__ import annotations
import argparse, re, time, os
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from concurrent.futures import ProcessPoolExecutor, as_completed

import pandas as pd
from openpyxl import load_workbook

# ---------------- Config ----------------
LIKELY_DATA_SHEETS = [
    "Banking & DFI", "Banking & DFI ", "Banking & DFI  ",
    "Insurance/Takaful", "Insurance & Takaful", "Data"
]
COVER_CELLS = {"entity": "F6", "year": "F7", "quarter": "F8"}

MONTHS_BY_Q = {
    "Quarter 1": ["Jan","Feb","Mar"], "Quarter 2": ["Apr","May","Jun"],
    "Quarter 3": ["Jul","Aug","Sep"], "Quarter 4": ["Oct","Nov","Dec"],
    "Q1":["Jan","Feb","Mar"], "Q2":["Apr","May","Jun"], "Q3":["Jul","Aug","Sep"], "Q4":["Oct","Nov","Dec"],
}
MONTH_COLS = ["C","D","E"]

WORKER_CATEGORIES = [
    "Managers","Professional","Technicians & Associate Professionals",
    "Clerical Occupations","Operative Workers","Elementary Occupations",
    "TOTAL Salary & Wages","TOTAL Basic Salary & Wages",
    "TOTAL Arrears to Basic Salary & Wages","TOTAL Bonus",
    "TOTAL Others (overtime, COLA, allowance, etc.)",
    "TOTAL Commissions Paid At Least Once a Month (RM)",
]

Q2A_BLOCKS = [
    ("Salary & Wages = A + B + C + D + E", "Salary & Wages = A+B+C+D+E"),
    ("A. Basic Salary & Wages",            "A. Basic Salary & Wages"),
    ("B. Arrears to Basic Salary & Wages", "B. Arrears to Basic Salary & Wages"),
    ("C. Bonus",                           "C. Bonus"),
    ("D. Others (overtime, COLA, allowance, etc.)", "D. Others (overtime, COLA, allowance, etc.)"),
    ("E. Commissions Paid At Least Once a Month (RM)", "E. Commissions Paid At Least Once a Month (RM)"),
]
Q2B_BLOCKS = [
    ("A. Salary & Wages", "A. Salary & Wages"),
    ("B. Commissions Paid At Least Once a Month (RM)", "B. Commissions Paid At Least Once a Month (RM)"),
]
JOB_FUNCTIONS = [
    "Banking Operations","Compliance","Corporate Banking","Credit Management",
    "Digital Banking & Innovation","Finance","Human Resources","Information Technology",
    "Internal Audit","Investment Banking","Legal","Retail Banking","Risk Management",
    "Sales and Marketing","Shariah","Treasury","Other functions"
]

# Narrow “fast windows” in the standard template (row ranges are inclusive)
FAST_WINDOWS = {
    "Q2A": (94, 170),   # covers the A..E blocks and totals
    "Q2B": (148, 166),  # covers Q2B (Islamic ops) blocks
    "Q2A_JF_Q4": (94, 200),  # job-function header & body live here in Q4
}

# ---------------- Utils ----------------
def _norm(s: object) -> str:
    if s is None: return ""
    s = str(s).replace("&", " and ")
    keep = "abcdefghijklmnopqrstuvwxyz0123456789()+/.:; -"
    return re.sub(r"\s+", " ", "".join(ch.lower() if ch.lower() in keep else " " for ch in s)).strip()

def _equals(a: object, b: str) -> bool:
    return _norm(a) == _norm(b)

@dataclass
class CoverMeta:
    entity: Optional[str]; year: Optional[int]; quarter_label: Optional[str]

def read_cover_meta(wb) -> CoverMeta:
    ent = yr = ql = None
    if "Cover" in wb.sheetnames:
        ws = wb["Cover"]
        try:
            ent = ws[COVER_CELLS["entity"]].value
            yr  = ws[COVER_CELLS["year"]].value
            ql  = ws[COVER_CELLS["quarter"]].value
        except Exception: pass
    if not ent or not yr or not ql:
        for s in wb.sheetnames[:3]:
            if s == "Cover": continue
            ws = wb[s]
            try:
                ent = ent or ws["C6"].value
                yr  = yr  or ws["C7"].value
                ql  = ql  or ws["C8"].value
            except Exception: pass
    try: yr = int(str(yr).strip()) if yr is not None else None
    except Exception: yr = None
    return CoverMeta(str(ent).strip() if ent else None, yr, str(ql).strip() if ql else None)

def pick_data_sheet(wb) -> str:
    names_norm = {_norm(s): s for s in wb.sheetnames}
    for want in LIKELY_DATA_SHEETS:
        if _norm(want) in names_norm: return names_norm[_norm(want)]
    for s in wb.sheetnames:
        if s != "Cover": return s
    return wb.sheetnames[0]

def read_number(ws, addr: str) -> float:
    try: v = ws[addr].value
    except Exception: return 0.0
    if v in (None,"","-"): return 0.0
    try: return float(v)
    except Exception:
        try: return float(str(v).replace(",",""))
        except Exception: return 0.0

# Build an index of column A once: normalized text -> list of row numbers
def build_colA_index(ws, start_row: int, end_row: int) -> Dict[str, List[int]]:
    idx: Dict[str, List[int]] = {}
    end = min(ws.max_row, end_row)
    start = max(1, start_row)
    for r in range(start, end + 1):
        key = _norm(ws.cell(r, 1).value)
        if key:
            idx.setdefault(key, []).append(r)
    return idx

def find_first_in_index(idx: Dict[str, List[int]], label: str) -> Optional[int]:
    rows = idx.get(_norm(label))
    return rows[0] if rows else None

# ---------------- Extraction ----------------
def extract_q2a_main(ws, meta: CoverMeta, fast=True) -> pd.DataFrame:
    months = MONTHS_BY_Q.get(meta.quarter_label or "", [])
    if len(months) != 3: return pd.DataFrame()
    win = FAST_WINDOWS["Q2A"] if fast else (1, ws.max_row)
    colA_idx = build_colA_index(ws, *win)

    # locate anchors quickly
    anchors: List[Tuple[str,int]] = []
    for label, alias in Q2A_BLOCKS:
        r = find_first_in_index(colA_idx, label)
        if r: anchors.append((label, r))
    if not anchors: return pd.DataFrame()
    anchors.sort(key=lambda x: x[1])

    wanted_norm = {_norm(w) for w in WORKER_CATEGORIES}
    out: List[Dict] = []

    for i, (label, start_r) in enumerate(anchors):
        subq = dict(Q2A_BLOCKS)[label]
        end_r = anchors[i+1][1] if i+1 < len(anchors) else min(ws.max_row, start_r + 150)
        r = start_r + 1
        while r < end_r:
            a = ws.cell(r, 1).value
            if _norm(a) in wanted_norm:
                v1 = read_number(ws, f"{MONTH_COLS[0]}{r}")
                v2 = read_number(ws, f"{MONTH_COLS[1]}{r}")
                v3 = read_number(ws, f"{MONTH_COLS[2]}{r}")
                out.append({
                    "entity_name": meta.entity, "year": meta.year, "quarter": meta.quarter_label,
                    "question": "Q2A", "subquestion": subq, "worker_category": str(a).strip(),
                    months[0]: v1, months[1]: v2, months[2]: v3,
                })
            r += 1
    return pd.DataFrame(out)

def extract_q2a_jobfunc_q4(ws, meta: CoverMeta, fast=True) -> pd.DataFrame:
    q = (meta.quarter_label or "").upper()
    if q not in ("Q4","QUARTER 4"): return pd.DataFrame()
    win = FAST_WINDOWS["Q2A_JF_Q4"] if fast else (1, ws.max_row)

    # Find header row with job functions within window only
    header_row = None; best = 0
    for r in range(win[0], min(ws.max_row, win[1]) + 1):
        row_vals = {_norm(ws.cell(r, c).value) for c in range(1, ws.max_column + 1)}
        hits = sum(1 for jf in JOB_FUNCTIONS if _norm(jf) in row_vals)
        if hits > best:
            best = hits; header_row = r
        if hits >= 8: break
    if not header_row: return pd.DataFrame()

    # Map job function -> col index
    jf_cols: Dict[str,int] = {}
    for c in range(1, ws.max_column + 1):
        txt = ws.cell(header_row, c).value
        for jf in JOB_FUNCTIONS:
            if _equals(txt, jf) and jf not in jf_cols:
                jf_cols[jf] = c
    if not jf_cols: return pd.DataFrame()

    # Build colA index below header to detect section headings & worker-category lines fast
    colA_idx = build_colA_index(ws, header_row + 1, min(ws.max_row, header_row + 220))
    section_labels = { _norm(a): name for a, name in Q2A_BLOCKS }
    wc_norm = {_norm(w) for w in WORKER_CATEGORIES}

    out: List[Dict] = []
    current_subq: Optional[str] = None
    end_scan = min(ws.max_row, header_row + 220)
    for r in range(header_row + 1, end_scan + 1):
        a = ws.cell(r, 1).value
        an = _norm(a)
        if an in section_labels:
            current_subq = section_labels[an]; continue
        if an in wc_norm:
            wc = str(a).strip()
            for jf, cidx in jf_cols.items():
                raw = ws.cell(r, cidx).value
                try: v = 0.0 if raw in (None,"","-") else float(str(raw).replace(",",""))
                except Exception: v = 0.0
                out.append({
                    "entity_name": meta.entity, "year": meta.year, "quarter": meta.quarter_label,
                    "question": "Q2A", "subquestion": current_subq or "", "worker_category": wc,
                    "job_function": jf, "value": v,
                })
    return pd.DataFrame(out)

def extract_q2b(ws, meta: CoverMeta, fast=True) -> pd.DataFrame:
    q = (meta.quarter_label or "").strip()
    if q not in ("Quarter 2","Quarter 4","Q2","Q4"): return pd.DataFrame()
    months = MONTHS_BY_Q.get(q, [])
    if not months: return pd.DataFrame()

    win = FAST_WINDOWS["Q2B"] if fast else (1, ws.max_row)
    colA_idx = build_colA_index(ws, *win)

    # anchors under Q2B
    anchors: List[Tuple[str,int]] = []
    for label, _ in Q2B_BLOCKS:
        r = find_first_in_index(colA_idx, label)
        if r: anchors.append((label, r))
    if not anchors: return pd.DataFrame()
    anchors.sort(key=lambda x: x[1])

    wc_norm = {_norm(w) for w in WORKER_CATEGORIES}
    out: List[Dict] = []
    for i, (label, start_r) in enumerate(anchors):
        subq = dict(Q2B_BLOCKS)[label]
        end_r = anchors[i+1][1] if i+1 < len(anchors) else min(ws.max_row, start_r + 80)
        r = start_r + 1
        while r < end_r:
            a = ws.cell(r, 1).value
            if _norm(a) in wc_norm:
                v1 = read_number(ws, f"{MONTH_COLS[0]}{r}")
                v2 = read_number(ws, f"{MONTH_COLS[1]}{r}")
                v3 = read_number(ws, f"{MONTH_COLS[2]}{r}")
                out.append({
                    "entity_name": meta.entity, "year": meta.year, "quarter": meta.quarter_label,
                    "question": "Q2B", "subquestion": subq, "worker_category": str(a).strip(),
                    months[0]: v1 if len(months)>0 else 0.0,
                    months[1]: v2 if len(months)>1 else 0.0,
                    months[2]: v3 if len(months)>2 else 0.0,
                })
            r += 1
    return pd.DataFrame(out)

# ------------- File driver (single file) -------------
def _extract_file(path: Path, fast: bool, skip_jobfunc: bool, verbose: bool) -> Tuple[str, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    try:
        wb = load_workbook(str(path), data_only=True, read_only=True)
    except Exception as e:
        if verbose: print(f"[ERROR] open {path.name}: {e}")
        return (path.name, pd.DataFrame(), pd.DataFrame(), pd.DataFrame())
    meta = read_cover_meta(wb)
    if not meta.entity or not meta.year or not meta.quarter_label:
        if verbose: print(f"[WARN] {path.name}: missing cover meta; skipping.")
        try: wb.close()
        except Exception: pass
        return (path.name, pd.DataFrame(), pd.DataFrame(), pd.DataFrame())
    ws = wb[pick_data_sheet(wb)]
    df_a  = extract_q2a_main(ws, meta, fast=fast)
    df_jf = pd.DataFrame() if skip_jobfunc else extract_q2a_jobfunc_q4(ws, meta, fast=fast)
    df_b  = extract_q2b(ws, meta, fast=fast)
    try: wb.close()
    except Exception: pass
    return (path.name, df_a, df_jf, df_b)

# ---------------- CLI ----------------
def main() -> int:
    ap = argparse.ArgumentParser(description="Turbo extract RLMS Question 2 (2A + 2B) → staging")
    ap.add_argument("--inputs", required=True, help="Folder with submissions")
    ap.add_argument("--out",    required=True, help="Output staging workbook (.xlsx)")
    ap.add_argument("--limit",  type=int, default=None, help="Limit files (debug)")
    ap.add_argument("--workers", type=int, default=0, help="Parallel processes (0 = cpu_count())")
    ap.add_argument("--no-fast", action="store_true", help="Disable fast narrow windows (use full-sheet scan)")
    ap.add_argument("--skip-jobfunc", action="store_true", help="Skip Q4 job-function extraction (faster)")
    ap.add_argument("--verbose", action="store_true")
    args = ap.parse_args()

    root = Path(args.inputs)
    if not root.exists():
        print(f"[ERROR] Folder not found: {root}"); return 2

    files: List[Path] = []
    for ext in ("*.xlsx","*.xlsm"):
        files.extend(p for p in root.rglob(ext) if not p.name.startswith("~$"))
    files.sort()
    if args.limit: files = files[:args.limit]
    print(f"[INFO] Files to scan: {len(files)}")

    t0 = time.perf_counter()
    fast = not args.no_fast
    workers = None if args.workers in (0, None) else args.workers

    rows_a, rows_jf, rows_b = [], [], []
    if workers is None or workers > 1:
        # parallel
        w = workers or os.cpu_count()
        print(f"[RUN] Parallel extraction with {w} workers")
        with ProcessPoolExecutor(max_workers=w) as ex:
            futs = {ex.submit(_extract_file, p, fast, args.skip_jobfunc, args.verbose): p for p in files}
            for i, fut in enumerate(as_completed(futs), 1):
                _, a, jf, b = fut.result()
                if not a.empty:  rows_a.append(a)
                if not jf.empty: rows_jf.append(jf)
                if not b.empty:  rows_b.append(b)
                if args.verbose and i % 25 == 0:
                    print(f"  processed {i}/{len(files)}")
    else:
        # serial
        for i, p in enumerate(files, 1):
            _, a, jf, b = _extract_file(p, fast, args.skip_jobfunc, args.verbose)
            if not a.empty:  rows_a.append(a)
            if not jf.empty: rows_jf.append(jf)
            if not b.empty:  rows_b.append(b)
            if args.verbose and i % 25 == 0:
                print(f"  processed {i}/{len(files)}")

    # concat once
    df_a  = pd.concat(rows_a,  ignore_index=True) if rows_a  else pd.DataFrame()
    df_jf = pd.concat(rows_jf, ignore_index=True) if rows_jf else pd.DataFrame()
    df_b  = pd.concat(rows_b,  ignore_index=True) if rows_b  else pd.DataFrame()

    # light sort
    def _sort(df: pd.DataFrame) -> pd.DataFrame:
        if df.empty: return df
        order = [c for c in ["entity_name","year","quarter","question","subquestion","worker_category","job_function"] if c in df.columns]
        months = [c for c in ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"] if c in df.columns]
        return df.sort_values(order + months, kind="mergesort").reset_index(drop=True)

    df_a  = _sort(df_a); df_jf = _sort(df_jf); df_b = _sort(df_b)

    out = Path(args.out); out.parent.mkdir(parents=True, exist_ok=True)
    with pd.ExcelWriter(out, engine="openpyxl") as xw:
        if not df_a.empty:  df_a.to_excel(xw, index=False, sheet_name="Q2A_Main")
        if not df_jf.empty: df_jf.to_excel(xw, index=False, sheet_name="Q2A_JobFunc_Q4")
        if not df_b.empty:  df_b.to_excel(xw, index=False, sheet_name="Q2B")
    print(f"[DONE] Wrote staging → {out}")
    print(f"[TIMER] {time.perf_counter()-t0:0.2f}s")
    return 0

if __name__ == "__main__":
    raise SystemExit(main())
